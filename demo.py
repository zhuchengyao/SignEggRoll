#!/usr/bin/env python3
"""
Diffusion Model for 3D Pose Generation - å¿«é€Ÿæ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºå¦‚ä½•ï¼š
1. åŠ è½½å’Œå¤„ç†å§¿æ€æ•°æ®
2. è®­ç»ƒä¸€ä¸ªç®€å•çš„diffusion model
3. ç”Ÿæˆæ–°çš„å§¿æ€æ ·æœ¬

ä½¿ç”¨æ–¹æ³•:
python demo.py --data_dir ./datasets/processed --quick_test
"""

import os
import sys
import argparse
import torch
import numpy as np
from pose_dataset import PoseDataset, visualize_pose_data
from diffusion_model import UNet1D, GaussianDiffusion
from train_diffusion import DiffusionTrainer
from generate_poses import PoseGenerator

def check_data_directory(data_dir):
    """æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨å’Œæœ‰æ•ˆ"""
    if not os.path.exists(data_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False
    
    # æŸ¥æ‰¾.skelsæ–‡ä»¶
    import glob
    skels_files = glob.glob(os.path.join(data_dir, "**", "*.skels"), recursive=True)
    
    if len(skels_files) == 0:
        print(f"âŒ åœ¨ç›®å½• {data_dir} ä¸­æœªæ‰¾åˆ° .skels æ–‡ä»¶")
        print("è¯·ç¡®ä¿æ•°æ®ç›®å½•åŒ…å« .skels æ ¼å¼çš„å§¿æ€æ•°æ®æ–‡ä»¶")
        return False
    
    print(f"âœ… æ‰¾åˆ° {len(skels_files)} ä¸ª .skels æ•°æ®æ–‡ä»¶")
    return True

def test_data_loading(data_dir, max_files=2):
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½...")
    
    try:
        # åˆ›å»ºæ•°æ®é›†ï¼ˆé™åˆ¶æ–‡ä»¶æ•°é‡ç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
        dataset = PoseDataset(
            data_dir=data_dir, 
            max_files=max_files,
            normalize=True,
            augment=False
        )
        
        if len(dataset) == 0:
            print("âŒ æ•°æ®é›†ä¸ºç©º")
            return None
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(dataset)} ä¸ªå§¿æ€å¸§")
        
        # æµ‹è¯•å•ä¸ªæ ·æœ¬
        sample = dataset[0]
        print(f"âœ… æ ·æœ¬å½¢çŠ¶: {sample.shape}")
        print(f"âœ… æ•°å€¼èŒƒå›´: [{sample.min():.4f}, {sample.max():.4f}]")
        
        # å¯è§†åŒ–å‡ ä¸ªæ ·æœ¬
        print("ğŸ“Š ç”Ÿæˆæ•°æ®å¯è§†åŒ–...")
        visualize_pose_data(dataset, num_samples=min(3, len(dataset)))
        
        return dataset
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def quick_train_test(dataset, device='cuda', epochs=50):
    """å¿«é€Ÿè®­ç»ƒæµ‹è¯•"""
    print(f"\nğŸš€ å¼€å§‹å¿«é€Ÿè®­ç»ƒæµ‹è¯• ({epochs} epochs)...")
    
    # åˆ›å»ºå°å‹æ¨¡å‹ç”¨äºå¿«é€Ÿæµ‹è¯•
    model = UNet1D(
        model_channels=64,  # å‡å°æ¨¡å‹ä»¥åŠ å¿«è®­ç»ƒ
        num_keypoints=67,
        channel_mult=(1, 2, 4)  # å‡å°‘å±‚æ•°
    )
    
    # åˆ›å»ºæ‰©æ•£è¿‡ç¨‹
    diffusion = GaussianDiffusion(
        num_timesteps=500,  # å‡å°‘æ—¶é—´æ­¥ä»¥åŠ å¿«è®­ç»ƒ
        beta_schedule='cosine'
    )
    
    # ç§»åŠ¨diffusionå‚æ•°åˆ°è®¾å¤‡
    diffusion.betas = diffusion.betas.to(device)
    diffusion.alphas = diffusion.alphas.to(device)
    diffusion.alphas_cumprod = diffusion.alphas_cumprod.to(device)
    diffusion.alphas_cumprod_prev = diffusion.alphas_cumprod_prev.to(device)
    diffusion.posterior_variance = diffusion.posterior_variance.to(device)
    
    # åˆ›å»ºä¸´æ—¶æ•°æ®ç›®å½•
    temp_data_dir = "temp_demo_data"
    os.makedirs(temp_data_dir, exist_ok=True)
    
    # ä¿å­˜æ•°æ®é›†çš„ä¸€å°éƒ¨åˆ†ç”¨äºè®­ç»ƒ
    sample_data_path = os.path.join(temp_data_dir, "demo_samples.skels")
    with open(sample_data_path, 'w') as f:
        for i in range(min(100, len(dataset))):  # æœ€å¤š100ä¸ªæ ·æœ¬
            pose = dataset.poses[i]  # è·å–åŸå§‹æœªæ ‡å‡†åŒ–çš„æ•°æ®
            flattened = pose.flatten()
            line = ' '.join([f'{x:.6f}' for x in flattened])
            f.write(line + '\n')
    
    print(f"ğŸ’¾ ä¿å­˜æ¼”ç¤ºæ•°æ®åˆ°: {sample_data_path}")
    
    try:
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = DiffusionTrainer(
            model=model,
            diffusion=diffusion,
            data_dir=temp_data_dir,
            device=device,
            batch_size=8,  # å°æ‰¹æ¬¡
            learning_rate=2e-4,
            num_epochs=epochs,
            save_interval=25,
            sample_interval=25,
            use_wandb=False  # å…³é—­wandbä»¥ç®€åŒ–
        )
        
        print("âœ… è®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
        
        # å¿«é€Ÿè®­ç»ƒ
        trainer.train()
        
        print("âœ… è®­ç»ƒå®Œæˆ!")
        return trainer.save_dir
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        return None
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(sample_data_path):
            os.remove(sample_data_path)
        if os.path.exists(temp_data_dir):
            os.rmdir(temp_data_dir)

def test_generation(checkpoint_dir, device='cuda'):
    """æµ‹è¯•å§¿æ€ç”Ÿæˆ"""
    print("\nğŸ¨ æµ‹è¯•å§¿æ€ç”Ÿæˆ...")
    
    # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹
    best_model_path = os.path.join(checkpoint_dir, "best_model.pth")
    latest_model_path = os.path.join(checkpoint_dir, "latest_checkpoint.pth")
    
    checkpoint_path = best_model_path if os.path.exists(best_model_path) else latest_model_path
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ£€æŸ¥ç‚¹: {checkpoint_path}")
        return False
    
    try:
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = PoseGenerator(checkpoint_path, device)
        print("âœ… ç”Ÿæˆå™¨åˆ›å»ºæˆåŠŸ")
        
        # ç”Ÿæˆå‡ ä¸ªæ ·æœ¬
        print("ğŸ¯ ç”Ÿæˆå§¿æ€æ ·æœ¬...")
        poses = generator.generate_poses(num_samples=4)
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(poses)} ä¸ªå§¿æ€æ ·æœ¬")
        
        # å¯è§†åŒ–ç»“æœ
        generator.visualize_poses(poses, "demo_generated_poses.png", "æ¼”ç¤ºï¼šç”Ÿæˆçš„å§¿æ€")
        
        # ä¿å­˜ç»“æœ
        generator.save_poses(poses, "demo_generated_poses.skels", "skels")
        
        print("âœ… ç”Ÿæˆæµ‹è¯•å®Œæˆ!")
        return True
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def print_usage_instructions():
    """æ‰“å°ä½¿ç”¨è¯´æ˜"""
    print("\n" + "="*60)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆ! ä¸‹é¢æ˜¯å®Œæ•´çš„ä½¿ç”¨è¯´æ˜:")
    print("="*60)
    
    print("\nğŸ“ 1. æ•°æ®å‡†å¤‡:")
    print("   å°†ä½ çš„ .skels æ–‡ä»¶æ”¾åœ¨æ•°æ®ç›®å½•ä¸­")
    print("   æ¯è¡Œåº”åŒ…å« 67*3=201 ä¸ªæµ®ç‚¹æ•°ï¼ˆ67ä¸ªå…³é”®ç‚¹çš„x,y,zåæ ‡ï¼‰")
    
    print("\nğŸš€ 2. è®­ç»ƒæ¨¡å‹:")
    print("   python train_diffusion.py --data_dir ./datasets/processed \\")
    print("                            --batch_size 32 \\")
    print("                            --num_epochs 1000 \\")
    print("                            --learning_rate 1e-4")
    
    print("\nğŸ¨ 3. ç”Ÿæˆå§¿æ€:")
    print("   python generate_poses.py --checkpoint ./checkpoints/best_model.pth \\")
    print("                            --num_samples 8 \\")
    print("                            --visualize")
    
    print("\nğŸ¬ 4. ç”ŸæˆåŠ¨ç”»:")
    print("   python generate_poses.py --checkpoint ./checkpoints/best_model.pth \\")
    print("                            --animation \\")
    print("                            --num_frames 30 \\")
    print("                            --visualize")
    
    print("\nğŸ“Š 5. æ•°æ®åˆ†æ:")
    print("   python pose_dataset.py  # æµ‹è¯•æ•°æ®åŠ è½½å’Œå¯è§†åŒ–")
    
    print("\nğŸ’¡ æç¤º:")
    print("   - ä½¿ç”¨ --no_wandb ç¦ç”¨ wandb æ—¥å¿—è®°å½•")
    print("   - ä½¿ç”¨ --device cpu åœ¨CPUä¸Šè¿è¡Œ")
    print("   - ä½¿ç”¨ --max_files N é™åˆ¶åŠ è½½çš„æ–‡ä»¶æ•°é‡ï¼ˆè°ƒè¯•ç”¨ï¼‰")
    
    print("\nğŸ“¦ é¡¹ç›®ç»“æ„:")
    print("   diffusion_model.py    - æ‰©æ•£æ¨¡å‹æ ¸å¿ƒå®ç°")
    print("   pose_dataset.py       - æ•°æ®åŠ è½½å’Œé¢„å¤„ç†")
    print("   train_diffusion.py    - è®­ç»ƒè„šæœ¬")
    print("   generate_poses.py     - ç”Ÿæˆè„šæœ¬")
    print("   demo.py              - æ¼”ç¤ºè„šæœ¬")
    print("   requirements.txt     - ä¾èµ–åŒ…åˆ—è¡¨")

def main():
    parser = argparse.ArgumentParser(description='Diffusion Model 3Då§¿æ€ç”Ÿæˆ - æ¼”ç¤ºè„šæœ¬')
    parser.add_argument('--data_dir', type=str, default='./datasets/processed', 
                       help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--device', type=str, default='cuda', 
                       help='è®¡ç®—è®¾å¤‡ (cuda/cpu)')
    parser.add_argument('--quick_test', action='store_true', 
                       help='æ‰§è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•')
    parser.add_argument('--epochs', type=int, default=50, 
                       help='å¿«é€Ÿæµ‹è¯•çš„è®­ç»ƒè½®æ•°')
    parser.add_argument('--skip_training', action='store_true', 
                       help='è·³è¿‡è®­ç»ƒï¼Œåªæµ‹è¯•æ•°æ®åŠ è½½')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è®¾å¤‡
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
        args.device = 'cpu'
    
    print("ğŸ¤– Diffusion Model 3Då§¿æ€ç”Ÿæˆ - æ¼”ç¤º")
    print(f"è®¾å¤‡: {args.device}")
    print(f"æ•°æ®ç›®å½•: {args.data_dir}")
    
    # 1. æ£€æŸ¥æ•°æ®ç›®å½•
    if not check_data_directory(args.data_dir):
        print("\nğŸ’¡ å»ºè®®:")
        print("   1. ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨")
        print("   2. ç¡®ä¿ç›®å½•ä¸­æœ‰ .skels æ ¼å¼çš„æ–‡ä»¶")
        print("   3. æ¯ä¸ª .skels æ–‡ä»¶æ¯è¡Œåº”æœ‰ 201 ä¸ªæµ®ç‚¹æ•°")
        return
    
    # 2. æµ‹è¯•æ•°æ®åŠ è½½
    dataset = test_data_loading(args.data_dir, max_files=2)
    if dataset is None:
        return
    
    # 3. å¦‚æœä¸è·³è¿‡è®­ç»ƒï¼Œè¿›è¡Œå¿«é€Ÿè®­ç»ƒæµ‹è¯•
    checkpoint_dir = None
    if not args.skip_training and args.quick_test:
        checkpoint_dir = quick_train_test(dataset, args.device, args.epochs)
        
        # 4. æµ‹è¯•ç”Ÿæˆ
        if checkpoint_dir:
            test_generation(checkpoint_dir, args.device)
    
    # 5. æ‰“å°ä½¿ç”¨è¯´æ˜
    print_usage_instructions()

if __name__ == "__main__":
    main() 