#!/usr/bin/env python3
"""
æ”¹è¿›çš„ SignLLM è®­ç»ƒè„šæœ¬
- æ·»åŠ éªŒè¯é›†è¯„ä¼°
- å¤åˆæŸå¤±å‡½æ•°
- å­¦ä¹ ç‡è°ƒåº¦
- æ—©åœæœºåˆ¶
- æ›´è¯¦ç»†çš„æ—¥å¿—è®°å½•
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import List, Dict, Tuple

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from improved_signllm_model import ImprovedSignLLM, ModelConfig
from data_processor import MultilingualSignDataset, collate_fn
from improved_evaluation import ImprovedSignLLMEvaluator
from pose_consistency_loss import PoseConsistencyLoss


class PoseLoss(nn.Module):
    """å¤åˆå§¿æ€æŸå¤±å‡½æ•° - é›†æˆäº†éª¨æ¶ç»“æ„çº¦æŸ"""
    
    def __init__(self, alpha=1.0, beta=0.5, gamma=0.3):
        super().__init__()
        self.alpha = alpha  # MSEæƒé‡
        self.beta = beta    # è¿åŠ¨å¹³æ»‘åº¦æƒé‡  
        self.gamma = gamma  # å§¿æ€ä¸€è‡´æ€§æƒé‡
        self.mse = nn.MSELoss()
        self.l1 = nn.L1Loss()
        
        # é›†æˆä¸“é—¨çš„å§¿æ€ä¸€è‡´æ€§æŸå¤±
        self.pose_consistency = PoseConsistencyLoss(
            bone_length_weight=0.2,
            joint_angle_weight=0.1,
            symmetry_weight=0.05,
            temporal_weight=0.1
        )
        
    def forward(self, pred_poses: torch.Tensor, target_poses: torch.Tensor) -> Dict[str, torch.Tensor]:
        # åŸºç¡€é‡å»ºæŸå¤±
        mse_loss = self.mse(pred_poses, target_poses)
        l1_loss = self.l1(pred_poses, target_poses)
        
        # è¿åŠ¨å¹³æ»‘åº¦æŸå¤±ï¼ˆç›¸é‚»å¸§å·®å¼‚ï¼‰
        pred_diff = pred_poses[:, 1:] - pred_poses[:, :-1]
        target_diff = target_poses[:, 1:] - target_poses[:, :-1]
        motion_loss = self.mse(pred_diff, target_diff)
        
        # å§¿æ€ä¸€è‡´æ€§æŸå¤±ï¼ˆä½¿ç”¨å®Œæ•´çš„éª¨æ¶çº¦æŸï¼‰
        consistency_losses = self.pose_consistency(pred_poses, target_poses)
        consistency_loss = consistency_losses['total']
        
        total_loss = (self.alpha * mse_loss + 
                     self.beta * motion_loss + 
                     self.gamma * consistency_loss)
        
        # è¿”å›è¯¦ç»†çš„æŸå¤±ä¿¡æ¯
        result = {
            'total': total_loss,
            'mse': mse_loss,
            'motion': motion_loss,
            'consistency': consistency_loss,
            'l1': l1_loss
        }
        
        # æ·»åŠ è¯¦ç»†çš„ä¸€è‡´æ€§æŸå¤±ä¿¡æ¯
        for key, value in consistency_losses.items():
            if key != 'total':
                result[f'consistency_{key}'] = value
        
        return result


class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    
    def __init__(self, patience=7, min_delta=0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = float('inf')
        
    def __call__(self, val_loss: float) -> bool:
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
            
        return self.counter >= self.patience


def validate_model(model: ImprovedSignLLM, val_loader: DataLoader, 
                  criterion: PoseLoss, evaluator: ImprovedSignLLMEvaluator,
                  device: torch.device) -> Dict[str, float]:
    """éªŒè¯æ¨¡å‹æ€§èƒ½"""
    model.eval()
    total_losses = {
        'total': 0, 'mse': 0, 'motion': 0, 'consistency': 0,
        'consistency_bone_length': 0, 'consistency_joint_angle': 0,
        'consistency_symmetry': 0, 'consistency_temporal': 0,
        'consistency_supervised': 0
    }
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Validating"):
            texts = batch["texts"]
            target_poses = batch["pose_sequences"].to(device)
            
            # Teacher Forcingæ¨¡å¼éªŒè¯
            results = model(
                texts=texts,
                language="ASL",
                target_poses=target_poses
            )
            pred_poses = results['predicted_poses']
            
            losses = criterion(pred_poses, target_poses)
            
            # ç´¯ç§¯æ‰€æœ‰æŸå¤±é¡¹
            for key in total_losses:
                if key in losses:
                    total_losses[key] += losses[key].item()
            
            # æ”¶é›†é¢„æµ‹å’Œç›®æ ‡ç”¨äºè¯¦ç»†è¯„ä¼°
            all_predictions.extend(pred_poses.cpu().numpy())
            all_targets.extend(target_poses.cpu().numpy())
    
    # è®¡ç®—å¹³å‡æŸå¤±
    avg_losses = {k: v / len(val_loader) for k, v in total_losses.items()}
    
    # è¯¦ç»†è¯„ä¼°æŒ‡æ ‡
    eval_metrics = evaluator.evaluate_poses(all_predictions, all_targets)
    
    return {**avg_losses, **eval_metrics}


def main():
    print("ğŸš€ æ”¹è¿›çš„ SignLLM è®­ç»ƒ")
    print("=" * 60)
    
    # é…ç½®
    MODEL_SIZE = "large"
    BATCH_SIZE = 4  # è°ƒå›åˆ°4ï¼Œ8å¯èƒ½å¯¼è‡´å†…å­˜é—®é¢˜
    LEARNING_RATE = 1e-4
    NUM_EPOCHS = 5
    PATIENCE = 10
    
    # è®¾å¤‡å’Œç›®å½•
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("checkpoints/improved_training")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # TensorBoardæ—¥å¿—
    writer = SummaryWriter(log_dir=output_dir / "logs")
    
    # æ¨¡å‹é…ç½®
    config = ModelConfig(MODEL_SIZE)
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ“¦ åˆ›å»ºæ¨¡å‹...")
    model = ImprovedSignLLM(languages=["ASL"]).to(device)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ“Š å‚æ•°é‡: {total_params:,} ({total_params/1_000_000:.1f}M)")
    
    # æ•°æ®é›†
    print("ğŸ“š åŠ è½½æ•°æ®é›†...")
    train_dataset = MultilingualSignDataset(
        data_dirs={"ASL": "datasets/signllm_data_complete"},
        languages=["ASL"],
        split="dev",
        max_sequence_length=config.default_max_frames,
        pose_dim=config.pose_dim,
    )
    
    val_dataset = MultilingualSignDataset(
        data_dirs={"ASL": "datasets/signllm_data_complete"},
        languages=["ASL"],
        split="test",  # æš‚æ—¶ä½¿ç”¨devä½œä¸ºéªŒè¯é›†ï¼ˆå› ä¸ºtestä¸å­˜åœ¨ï¼‰
        max_sequence_length=config.default_max_frames,
        pose_dim=config.pose_dim,
    )
    
    train_loader = DataLoader(
        train_dataset, batch_size=BATCH_SIZE, shuffle=True,
        num_workers=2, collate_fn=collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset, batch_size=BATCH_SIZE, shuffle=False,
        num_workers=2, collate_fn=collate_fn
    )
    
    print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬: {len(train_dataset)}, éªŒè¯æ ·æœ¬: {len(val_dataset)}")
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±
    criterion = PoseLoss(alpha=1.0, beta=0.5, gamma=1)
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5, verbose=True
    )
    scaler = torch.amp.GradScaler(device.type)
    
    # è¯„ä¼°å™¨å’Œæ—©åœ
    evaluator = ImprovedSignLLMEvaluator()
    early_stopping = EarlyStopping(patience=PATIENCE)
    
    # è®­ç»ƒå¾ªç¯
    best_val_loss = float('inf')
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    
    for epoch in range(NUM_EPOCHS):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        epoch_losses = {
            'total': 0, 'mse': 0, 'motion': 0, 'consistency': 0,
            'consistency_bone_length': 0, 'consistency_joint_angle': 0,
            'consistency_symmetry': 0, 'consistency_temporal': 0
        }
        
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS}")
        for batch_idx, batch in enumerate(train_pbar):
            texts = batch["texts"]
            target_poses = batch["pose_sequences"].to(device)
            
            with torch.amp.autocast(device.type):
                results = model(
                    texts=texts,
                    language="ASL",
                    target_poses=target_poses
                )
                pred_poses = results['predicted_poses']
                losses = criterion(pred_poses, target_poses)
            
            optimizer.zero_grad()
            scaler.scale(losses['total']).backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            scaler.step(optimizer)
            scaler.update()
            
            # è®°å½•æŸå¤±
            for key in epoch_losses:
                if key in losses:
                    epoch_losses[key] += losses[key].item()
            
            # æ›´æ–°è¿›åº¦æ¡
            current_loss = losses['total'].item()
            train_pbar.set_postfix({'loss': f'{current_loss:.4f}'})
            
            # è®°å½•åˆ°TensorBoard
            step = epoch * len(train_loader) + batch_idx
            writer.add_scalar('Train/Loss', current_loss, step)
        
        # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
        avg_train_losses = {k: v / len(train_loader) for k, v in epoch_losses.items()}
        
        # éªŒè¯é˜¶æ®µ
        val_metrics = validate_model(model, val_loader, criterion, evaluator, device)
        val_loss = val_metrics['total']
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(val_loss)
        
        # è®°å½•åˆ°TensorBoard
        for key, value in avg_train_losses.items():
            writer.add_scalar(f'Train/{key.capitalize()}Loss', value, epoch)
        for key, value in val_metrics.items():
            writer.add_scalar(f'Val/{key.capitalize()}', value, epoch)
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š Epoch {epoch+1}/{NUM_EPOCHS}:")
        print(f"  è®­ç»ƒæŸå¤±: {avg_train_losses['total']:.6f}")
        print(f"  éªŒè¯æŸå¤±: {val_loss:.6f}")
        print(f"  DTWåˆ†æ•°: {val_metrics.get('dtw_score', 0):.4f}")
        print(f"  å§¿æ€ç›¸ä¼¼åº¦: {val_metrics.get('pose_similarity', 0):.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'config': config.__dict__,
                'val_loss': val_loss,
                'val_metrics': val_metrics
            }
            torch.save(checkpoint, output_dir / 'best_model.pth')
            print("ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹")
        
        # æ—©åœæ£€æŸ¥
        if early_stopping(val_loss):
            print(f"ğŸ›‘ æ—©åœè§¦å‘ (epoch {epoch+1})")
            break
    
    writer.close()
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")
    
    # æœ€ç»ˆæµ‹è¯•
    print("\nğŸ” æœ€ç»ˆæ¨ç†æµ‹è¯•...")
    model.eval()
    model.set_inference_mode(True)
    with torch.no_grad():
        test_texts = ["Hello world", "How are you?"]
        results = model(texts=test_texts, language="ASL")
        test_poses = results['predicted_poses']
        print(f"âœ… æ¨ç†æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {test_poses.shape}")


if __name__ == "__main__":
    main() 