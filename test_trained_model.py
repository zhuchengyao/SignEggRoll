#!/usr/bin/env python3
"""
æµ‹è¯•è®­ç»ƒå¥½çš„SignLLMæ¨¡å‹
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).parent))
from signllm_model import SignLLM


def load_trained_model(checkpoint_path):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    # åˆ›å»ºæ¨¡å‹
    model = SignLLM(
        languages=["ASL"],
        gloss_vocab_size=1000,
        hidden_dim=256,
        pose_dim=150
    )
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    model.load_state_dict(checkpoint['model_state_dict'])
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®­ç»ƒepoch: {checkpoint['epoch']}, æŸå¤±: {checkpoint['loss']:.6f}")
    
    return model


def test_model_inference(model, test_texts):
    """æµ‹è¯•æ¨¡å‹æ¨ç†"""
    model.eval()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    
    results = []
    
    with torch.no_grad():
        for text in test_texts:
            print(f"\nğŸ” æµ‹è¯•æ–‡æœ¬: '{text}'")
            
            # MLSFæ¨¡å¼
            poses_mlsf, quality_mlsf = model(
                texts=[text],
                language="ASL",
                mode="mlsf",
                max_length=30
            )
            
            # Prompt2LangGlossæ¨¡å¼
            poses_p2lg, gloss_logits, quality_p2lg = model(
                texts=[text],
                language="ASL",
                mode="prompt2langgloss",
                max_pose_length=30,
                max_gloss_length=20
            )
            
            results.append({
                'text': text,
                'mlsf_poses': poses_mlsf.cpu().numpy(),
                'mlsf_quality': quality_mlsf.cpu().numpy(),
                'p2lg_poses': poses_p2lg.cpu().numpy(),
                'p2lg_gloss': gloss_logits.cpu().numpy(),
                'p2lg_quality': quality_p2lg.cpu().numpy()
            })
            
            print(f"  MLSFå§¿æ€å½¢çŠ¶: {poses_mlsf.shape}")
            print(f"  MLSFè´¨é‡åˆ†æ•°: {quality_mlsf.mean().item():.4f}")
            print(f"  P2LGå§¿æ€å½¢çŠ¶: {poses_p2lg.shape}")
            print(f"  P2LGè´¨é‡åˆ†æ•°: {quality_p2lg.mean().item():.4f}")
    
    return results


def visualize_poses(results, save_path="pose_analysis.png"):
    """å¯è§†åŒ–ç”Ÿæˆçš„å§¿æ€"""
    fig, axes = plt.subplots(2, len(results), figsize=(5*len(results), 8))
    if len(results) == 1:
        axes = axes.reshape(-1, 1)
    
    for i, result in enumerate(results):
        text = result['text']
        mlsf_poses = result['mlsf_poses'][0]  # [frames, 150]
        p2lg_poses = result['p2lg_poses'][0]  # [frames, 150]
        
        # MLSFæ¨¡å¼å§¿æ€è½¨è¿¹
        ax1 = axes[0, i]
        # æ˜¾ç¤ºå‰10ä¸ªå…³é”®ç‚¹çš„è½¨è¿¹
        for j in range(min(10, mlsf_poses.shape[1]//3)):
            x_coords = mlsf_poses[:, j*3]
            y_coords = mlsf_poses[:, j*3+1]
            ax1.plot(x_coords, y_coords, alpha=0.7, label=f'Point {j}')
        
        ax1.set_title(f'MLSFæ¨¡å¼\n"{text[:20]}..."')
        ax1.set_xlabel('Xåæ ‡')
        ax1.set_ylabel('Yåæ ‡')
        ax1.grid(True)
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # Prompt2LangGlossæ¨¡å¼å§¿æ€è½¨è¿¹
        ax2 = axes[1, i]
        for j in range(min(10, p2lg_poses.shape[1]//3)):
            x_coords = p2lg_poses[:, j*3]
            y_coords = p2lg_poses[:, j*3+1]
            ax2.plot(x_coords, y_coords, alpha=0.7, label=f'Point {j}')
        
        ax2.set_title(f'Prompt2LangGlossæ¨¡å¼\n"{text[:20]}..."')
        ax2.set_xlabel('Xåæ ‡')
        ax2.set_ylabel('Yåæ ‡')
        ax2.grid(True)
        ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.show()
    print(f"ğŸ“Š å§¿æ€å¯è§†åŒ–å·²ä¿å­˜: {save_path}")


def analyze_model_performance(results):
    """åˆ†ææ¨¡å‹æ€§èƒ½"""
    print("\nğŸ“ˆ æ¨¡å‹æ€§èƒ½åˆ†æ")
    print("=" * 50)
    
    for result in results:
        text = result['text']
        mlsf_poses = result['mlsf_poses'][0]
        p2lg_poses = result['p2lg_poses'][0]
        
        print(f"\nğŸ“ æ–‡æœ¬: '{text}'")
        
        # è¿åŠ¨å¹…åº¦åˆ†æ
        mlsf_motion = np.std(mlsf_poses, axis=0).mean()
        p2lg_motion = np.std(p2lg_poses, axis=0).mean()
        
        print(f"  MLSFè¿åŠ¨å¹…åº¦: {mlsf_motion:.4f}")
        print(f"  P2LGè¿åŠ¨å¹…åº¦: {p2lg_motion:.4f}")
        
        # å¹³æ»‘åº¦åˆ†æ
        mlsf_smoothness = np.mean(np.abs(np.diff(mlsf_poses, axis=0)))
        p2lg_smoothness = np.mean(np.abs(np.diff(p2lg_poses, axis=0)))
        
        print(f"  MLSFå¹³æ»‘åº¦: {mlsf_smoothness:.4f}")
        print(f"  P2LGå¹³æ»‘åº¦: {p2lg_smoothness:.4f}")
        
        # è´¨é‡åˆ†æ•°
        mlsf_quality = result['mlsf_quality'].mean()
        p2lg_quality = result['p2lg_quality'].mean()
        
        print(f"  MLSFè´¨é‡åˆ†æ•°: {mlsf_quality:.4f}")
        print(f"  P2LGè´¨é‡åˆ†æ•°: {p2lg_quality:.4f}")


def main():
    print("ğŸ§ª æµ‹è¯•è®­ç»ƒå¥½çš„SignLLMæ¨¡å‹")
    print("=" * 50)
    
    # åŠ è½½æœ€æ–°çš„æ¨¡å‹
    checkpoint_path = "checkpoints/minimal_train/epoch_3.pth"
    
    if not Path(checkpoint_path).exists():
        print(f"âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return
    
    model = load_trained_model(checkpoint_path)
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "Hello world",
        "How are you?",
        "Thank you very much",
        "Good morning"
    ]
    
    print(f"\nğŸ” æµ‹è¯• {len(test_texts)} ä¸ªæ–‡æœ¬...")
    
    # æ¨ç†æµ‹è¯•
    results = test_model_inference(model, test_texts)
    
    # æ€§èƒ½åˆ†æ
    analyze_model_performance(results)
    
    # å¯è§†åŒ–
    print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–...")
    visualize_poses(results[:2])  # åªå¯è§†åŒ–å‰2ä¸ªç»“æœ
    
    print("\nğŸ‰ æ¨¡å‹æµ‹è¯•å®Œæˆï¼")
    print("ğŸ’¡ æ‚¨çš„SignLLMæ¨¡å‹å·²ç»å¯ä»¥å°†æ–‡æœ¬è½¬æ¢ä¸ºæ‰‹è¯­å§¿æ€åºåˆ—äº†ï¼")


if __name__ == "__main__":
    main() 