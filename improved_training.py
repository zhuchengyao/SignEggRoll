#!/usr/bin/env python3
"""
æ”¹è¿›çš„SignLLMè®­ç»ƒè„šæœ¬
åŒ…å«å¤šç§ä¼˜åŒ–æŠ€æœ¯ä»¥çªç ´è®­ç»ƒç“¶é¢ˆ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts
import numpy as np
import json
import math
from pathlib import Path
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
from tqdm import tqdm
import logging

from signllm_model import SignLLM, ModelConfig, CONFIG, AdvancedRLLoss
from data_processor import SignLanguageDataset  # å‡è®¾ä½ æœ‰è¿™ä¸ªæ•°æ®åŠ è½½å™¨


class ImprovedTrainer:
    """æ”¹è¿›çš„è®­ç»ƒå™¨"""
    
    def __init__(self, model_size: str = "medium", use_advanced_loss: bool = True):
        """
        Args:
            model_size: æ¨¡å‹å¤§å° ("small", "medium", "large", "xl")
            use_advanced_loss: æ˜¯å¦ä½¿ç”¨æ”¹è¿›çš„æŸå¤±å‡½æ•°
        """
        # æ›´æ–°é…ç½®
        global CONFIG
        CONFIG.__init__(model_size)
        CONFIG.print_config()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = SignLLM(languages=["ASL"])
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        
        # æŸå¤±å‡½æ•°
        if use_advanced_loss:
            self.criterion = AdvancedRLLoss(
                alpha=0.15,   # è´¨é‡æƒé‡
                beta=0.1,     # å¤šæ ·æ€§æƒé‡  
                gamma=0.08,   # å¹³æ»‘æ€§æƒé‡
                delta=0.03    # ä¸€è‡´æ€§æƒé‡
            )
            print("âœ… ä½¿ç”¨æ”¹è¿›çš„AdvancedRLLossæŸå¤±å‡½æ•°")
        else:
            self.criterion = nn.MSELoss()
            print("âœ… ä½¿ç”¨æ ‡å‡†MSEæŸå¤±å‡½æ•°")
        
        # è®¾ç½®ä¼˜åŒ–å™¨ - ä½¿ç”¨AdamW + åˆ†å±‚å­¦ä¹ ç‡
        self.setup_optimizer()
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.best_loss = float('inf')
        self.train_losses = []
        self.val_losses = []
        self.learning_rates = []
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
    def setup_optimizer(self):
        """è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        # åˆ†å±‚å­¦ä¹ ç‡ï¼šBERTç”¨è¾ƒå°å­¦ä¹ ç‡ï¼Œæ–°å‚æ•°ç”¨è¾ƒå¤§å­¦ä¹ ç‡
        bert_params = []
        other_params = []
        
        for name, param in self.model.named_parameters():
            if 'encoder.encoder' in name:  # BERTå‚æ•°
                bert_params.append(param)
            else:  # å…¶ä»–å‚æ•°
                other_params.append(param)
        
        # åŸºç¡€å­¦ä¹ ç‡
        base_lr = self.get_optimal_lr()
        
        # å‚æ•°ç»„
        param_groups = [
            {'params': bert_params, 'lr': base_lr * 0.1, 'weight_decay': CONFIG.weight_decay * 0.5},  # BERTç”¨å°å­¦ä¹ ç‡
            {'params': other_params, 'lr': base_lr, 'weight_decay': CONFIG.weight_decay}  # å…¶ä»–å‚æ•°
        ]
        
        # AdamWä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            param_groups,
            betas=(0.9, 0.999),
            eps=1e-8,
            amsgrad=True  # æé«˜ç¨³å®šæ€§
        )
        
        print(f"âœ… ä¼˜åŒ–å™¨è®¾ç½®å®Œæˆ")
        print(f"   BERTå­¦ä¹ ç‡: {base_lr * 0.1:.2e}")
        print(f"   å…¶ä»–å‚æ•°å­¦ä¹ ç‡: {base_lr:.2e}")
        print(f"   æƒé‡è¡°å‡: {CONFIG.weight_decay}")
        
    def get_optimal_lr(self) -> float:
        """æ ¹æ®æ¨¡å‹å¤§å°è·å–æœ€ä¼˜å­¦ä¹ ç‡"""
        lr_map = {
            "tiny": 3e-4,
            "small": 2e-4, 
            "medium": 1e-4,
            "large": 8e-5,
            "xl": 5e-5
        }
        return lr_map.get(CONFIG.model_size, 1e-4)
    
    def setup_scheduler(self, total_steps: int):
        """è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨"""
        # ä½¿ç”¨OneCycleLRè¿›è¡Œå­¦ä¹ ç‡è°ƒåº¦
        self.scheduler = OneCycleLR(
            self.optimizer,
            max_lr=[group['lr'] for group in self.optimizer.param_groups],
            total_steps=total_steps,
            pct_start=0.1,  # 10%çš„æ­¥æ•°ç”¨äºé¢„çƒ­
            anneal_strategy='cos',
            div_factor=25.0,  # åˆå§‹å­¦ä¹ ç‡ = max_lr / div_factor
            final_div_factor=1000.0  # æœ€ç»ˆå­¦ä¹ ç‡ = max_lr / final_div_factor
        )
        
        print(f"âœ… å­¦ä¹ ç‡è°ƒåº¦å™¨è®¾ç½®å®Œæˆ")
        print(f"   æ€»æ­¥æ•°: {total_steps}")
        print(f"   é¢„çƒ­æ¯”ä¾‹: 10%")
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('improved_training.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def compute_loss(self, pred_poses: torch.Tensor, target_poses: torch.Tensor, 
                    quality_scores: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor:
        """è®¡ç®—æŸå¤±"""
        if isinstance(self.criterion, AdvancedRLLoss):
            return self.criterion(pred_poses, target_poses, quality_scores, mask)
        else:
            return self.criterion(pred_poses, target_poses)
    
    def train_epoch(self, dataloader: DataLoader) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        num_batches = len(dataloader)
        
        progress_bar = tqdm(dataloader, desc=f"Epoch {self.current_epoch}")
        
        for batch_idx, batch in enumerate(progress_bar):
            # è§£åŒ…æ•°æ®
            texts = batch['text']
            target_poses = batch['poses'].to(self.device)  # [batch_size, seq_len, 150]
            mask = batch.get('mask', None)
            if mask is not None:
                mask = mask.to(self.device)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            
            try:
                # æ¨¡å‹é¢„æµ‹
                pred_poses, quality_scores = self.model(
                    texts=texts, 
                    language="ASL", 
                    mode="mlsf",
                    max_length=target_poses.size(1)
                )
                
                # è®¡ç®—æŸå¤±
                loss = self.compute_loss(pred_poses, target_poses, quality_scores, mask)
                
                # åå‘ä¼ æ’­
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), CONFIG.gradient_clip)
                
                # ä¼˜åŒ–å™¨æ­¥è¿›
                self.optimizer.step()
                
                # å­¦ä¹ ç‡è°ƒåº¦
                if hasattr(self, 'scheduler'):
                    self.scheduler.step()
                    current_lr = self.scheduler.get_last_lr()[0]
                    self.learning_rates.append(current_lr)
                
                # ç´¯ç§¯æŸå¤±
                total_loss += loss.item()
                
                # æ›´æ–°è¿›åº¦æ¡
                avg_loss = total_loss / (batch_idx + 1)
                progress_bar.set_postfix({
                    'loss': f'{loss.item():.6f}',
                    'avg_loss': f'{avg_loss:.6f}',
                    'lr': f'{current_lr:.2e}' if hasattr(self, 'scheduler') else 'N/A'
                })
                
            except RuntimeError as e:
                self.logger.error(f"è®­ç»ƒé”™è¯¯: {e}")
                continue
        
        avg_loss = total_loss / num_batches
        self.train_losses.append(avg_loss)
        
        return avg_loss
    
    def validate(self, dataloader: DataLoader) -> float:
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0.0
        num_batches = len(dataloader)
        
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="éªŒè¯ä¸­"):
                texts = batch['text']
                target_poses = batch['poses'].to(self.device)
                mask = batch.get('mask', None)
                if mask is not None:
                    mask = mask.to(self.device)
                
                try:
                    # æ¨¡å‹é¢„æµ‹
                    pred_poses, quality_scores = self.model(
                        texts=texts,
                        language="ASL",
                        mode="mlsf", 
                        max_length=target_poses.size(1)
                    )
                    
                    # è®¡ç®—æŸå¤±
                    loss = self.compute_loss(pred_poses, target_poses, quality_scores, mask)
                    total_loss += loss.item()
                    
                except RuntimeError as e:
                    self.logger.error(f"éªŒè¯é”™è¯¯: {e}")
                    continue
        
        avg_loss = total_loss / num_batches
        self.val_losses.append(avg_loss)
        
        return avg_loss
    
    def save_checkpoint(self, filepath: str, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': self.current_epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if hasattr(self, 'scheduler') else None,
            'best_loss': self.best_loss,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'config': CONFIG.__dict__
        }
        
        torch.save(checkpoint, filepath)
        
        if is_best:
            best_path = str(Path(filepath).parent / "best_model.pth")
            torch.save(checkpoint, best_path)
            self.logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_path}")
    
    def load_checkpoint(self, filepath: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(filepath, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if checkpoint.get('scheduler_state_dict') and hasattr(self, 'scheduler'):
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.current_epoch = checkpoint['epoch']
        self.best_loss = checkpoint['best_loss']
        self.train_losses = checkpoint.get('train_losses', [])
        self.val_losses = checkpoint.get('val_losses', [])
        
        self.logger.info(f"âœ… åŠ è½½æ£€æŸ¥ç‚¹: epoch {self.current_epoch}, best_loss: {self.best_loss:.6f}")
    
    def plot_training_curves(self, save_path: str = "training_curves.png"):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # æŸå¤±æ›²çº¿
        if self.train_losses:
            axes[0, 0].plot(self.train_losses, label='Train Loss', color='blue')
        if self.val_losses:
            axes[0, 0].plot(self.val_losses, label='Val Loss', color='red')
        axes[0, 0].set_title('æŸå¤±æ›²çº¿')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # å­¦ä¹ ç‡æ›²çº¿
        if self.learning_rates:
            axes[0, 1].plot(self.learning_rates, color='green')
            axes[0, 1].set_title('å­¦ä¹ ç‡å˜åŒ–')
            axes[0, 1].set_xlabel('Step')
            axes[0, 1].set_ylabel('Learning Rate')
            axes[0, 1].grid(True)
        
        # æŸå¤±å¯¹æ¯” (æœ€è¿‘çš„epochs)
        if len(self.train_losses) > 10:
            recent_train = self.train_losses[-10:]
            recent_val = self.val_losses[-10:] if len(self.val_losses) >= 10 else self.val_losses
            axes[1, 0].plot(recent_train, 'o-', label='Recent Train', color='blue')
            if recent_val:
                axes[1, 0].plot(recent_val, 'o-', label='Recent Val', color='red')
            axes[1, 0].set_title('æœ€è¿‘10è½®æŸå¤±')
            axes[1, 0].legend()
            axes[1, 0].grid(True)
        
        # è®­ç»ƒç»Ÿè®¡
        if self.train_losses:
            min_loss = min(self.train_losses)
            best_epoch = self.train_losses.index(min_loss)
            improvement = self.train_losses[0] - min_loss if len(self.train_losses) > 1 else 0
            
            stats_text = f"""è®­ç»ƒç»Ÿè®¡:
æœ€ä½³è®­ç»ƒæŸå¤±: {min_loss:.6f}
æœ€ä½³è½®æ¬¡: {best_epoch}
æ€»æ”¹è¿›: {improvement:.6f}
å½“å‰è½®æ¬¡: {self.current_epoch}
æ¨¡å‹å¤§å°: {CONFIG.model_size}"""
            
            axes[1, 1].text(0.1, 0.5, stats_text, fontsize=12, 
                           bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))
            axes[1, 1].set_title('è®­ç»ƒç»Ÿè®¡')
            axes[1, 1].axis('off')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_path}")
    
    def train(self, train_dataloader: DataLoader, val_dataloader: DataLoader = None,
              num_epochs: int = 50, save_dir: str = "improved_checkpoints"):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        save_dir = Path(save_dir)
        save_dir.mkdir(exist_ok=True)
        
        # è®¡ç®—æ€»æ­¥æ•°å¹¶è®¾ç½®è°ƒåº¦å™¨
        total_steps = len(train_dataloader) * num_epochs
        self.setup_scheduler(total_steps)
        
        self.logger.info(f"ğŸš€ å¼€å§‹æ”¹è¿›è®­ç»ƒ")
        self.logger.info(f"   æ¨¡å‹å¤§å°: {CONFIG.model_size}")
        self.logger.info(f"   æ€»è½®æ¬¡: {num_epochs}")
        self.logger.info(f"   æ€»æ­¥æ•°: {total_steps}")
        self.logger.info(f"   ä¿å­˜ç›®å½•: {save_dir}")
        
        patience = 10  # æ—©åœè€å¿ƒ
        patience_counter = 0
        
        for epoch in range(num_epochs):
            self.current_epoch = epoch
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(train_dataloader)
            
            # éªŒè¯
            val_loss = None
            if val_dataloader:
                val_loss = self.validate(val_dataloader)
                self.logger.info(f"Epoch {epoch}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}")
            else:
                self.logger.info(f"Epoch {epoch}: Train Loss = {train_loss:.6f}")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
            current_loss = val_loss if val_loss is not None else train_loss
            is_best = current_loss < self.best_loss
            
            if is_best:
                self.best_loss = current_loss
                patience_counter = 0
                self.logger.info(f"ğŸ‰ æ–°çš„æœ€ä½³æŸå¤±: {self.best_loss:.6f}")
            else:
                patience_counter += 1
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint_path = save_dir / f"epoch_{epoch}.pth"
            self.save_checkpoint(str(checkpoint_path), is_best)
            
            # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
            if epoch % 5 == 0:
                self.plot_training_curves(str(save_dir / f"training_curves_epoch_{epoch}.png"))
            
            # æ—©åœæ£€æŸ¥
            if patience_counter >= patience:
                self.logger.info(f"â¹ï¸  æ—©åœè§¦å‘ï¼Œè¿ç»­{patience}è½®æ— æ”¹è¿›")
                break
        
        # æœ€ç»ˆä¿å­˜
        final_path = save_dir / "final_model.pth"
        self.save_checkpoint(str(final_path))
        self.plot_training_curves(str(save_dir / "final_training_curves.png"))
        
        self.logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼æœ€ä½³æŸå¤±: {self.best_loss:.6f}")


def main():
    """ä¸»å‡½æ•° - ä½¿ç”¨æ”¹è¿›çš„è®­ç»ƒå™¨"""
    
    # è®­ç»ƒé…ç½®
    BATCH_SIZE = 8  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
    NUM_EPOCHS = 100
    MODEL_SIZE = "medium"  # å°è¯•æ›´å¤§çš„æ¨¡å‹
    
    print("ğŸ”§ è®¾ç½®æ”¹è¿›è®­ç»ƒ")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ImprovedTrainer(
        model_size=MODEL_SIZE,
        use_advanced_loss=True
    )
    
    # TODO: åŠ è½½ä½ çš„æ•°æ®é›†
    # train_dataset = SignLanguageDataset("datasets/signllm_data_complete/ASL/train/")
    # val_dataset = SignLanguageDataset("datasets/signllm_data_complete/ASL/dev/")
    # 
    # train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    # val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
    
    print("âš ï¸  è¯·æ ¹æ®ä½ çš„æ•°æ®é›†è·¯å¾„ä¿®æ”¹æ•°æ®åŠ è½½éƒ¨åˆ†")
    print("   ç„¶åè¿è¡Œ: trainer.train(train_dataloader, val_dataloader, NUM_EPOCHS)")
    
    # ç¤ºä¾‹ï¼šå¦‚æœä½ æœ‰æ£€æŸ¥ç‚¹è¦ç»§ç»­è®­ç»ƒ
    # if Path("improved_checkpoints/epoch_10.pth").exists():
    #     trainer.load_checkpoint("improved_checkpoints/epoch_10.pth")
    
    # å¼€å§‹è®­ç»ƒ
    # trainer.train(train_dataloader, val_dataloader, NUM_EPOCHS)


if __name__ == "__main__":
    main() 