#!/usr/bin/env python3
"""
SignLLM å¿«é€Ÿè®­ç»ƒè„šæœ¬ - ç”¨äºéªŒè¯è®­ç»ƒæµç¨‹
"""

import os
import sys
import json
import torch
import torch.nn as nn
import torch.optim as optim
from pathlib import Path
import numpy as np
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from signllm_model import SignLLM
from data_processor import MultilingualSignDataset


def main():
    print("ğŸš€ SignLLM å¿«é€Ÿè®­ç»ƒéªŒè¯")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name()}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    # æ£€æŸ¥æ•°æ®
    data_path = Path("datasets/signllm_data_complete")
    if not data_path.exists():
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
        print("è¯·å…ˆè¿è¡Œæ•°æ®è½¬æ¢è„šæœ¬")
        return
    
    asl_dev_path = data_path / "ASL" / "dev"
    if not asl_dev_path.exists():
        print(f"âŒ ASL devæ•°æ®ä¸å­˜åœ¨: {asl_dev_path}")
        return
    
    sample_count = len([d for d in asl_dev_path.iterdir() if d.is_dir()])
    print(f"âœ… æ‰¾åˆ° {sample_count} ä¸ªASLæ ·æœ¬")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ“¦ åˆ›å»ºæ¨¡å‹...")
    model = SignLLM(
        languages=["ASL"],
        gloss_vocab_size=1000,
        hidden_dim=256,
        pose_dim=150
    ).to(device)
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,}")
    
    # åˆ›å»ºæ•°æ®é›†
    print("\nğŸ“š åˆ›å»ºæ•°æ®é›†...")
    try:
        dataset = MultilingualSignDataset(
            data_dirs={"ASL": str(data_path)},
            languages=["ASL"],
            split="dev",
            max_sequence_length=200,
            pose_dim=150
        )
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ: {len(dataset)} æ ·æœ¬")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    print("\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½...")
    try:
        sample = dataset[0]
        print(f"âœ… æ ·æœ¬åŠ è½½æˆåŠŸ:")
        print(f"   æ–‡æœ¬: {sample['text'][:50]}...")
        print(f"   å§¿æ€å½¢çŠ¶: {sample['pose_sequence'].shape}")
        print(f"   è¯­è¨€: {sample['language']}")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = optim.AdamW(model.parameters(), lr=1e-4)
    criterion = nn.MSELoss()
    
    # å¿«é€Ÿè®­ç»ƒ
    print("\nğŸ¯ å¼€å§‹å¿«é€Ÿè®­ç»ƒï¼ˆ3ä¸ªepochï¼‰...")
    model.train()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    checkpoint_dir = Path("checkpoints/quick_train")
    checkpoint_dir.mkdir(parents=True, exist_ok=True)
    
    for epoch in range(3):
        print(f"\nğŸ“… Epoch {epoch+1}/3")
        epoch_loss = 0
        num_batches = 0
        
        # ä½¿ç”¨å‰20ä¸ªæ ·æœ¬è¿›è¡Œå¿«é€Ÿè®­ç»ƒ
        max_samples = min(20, len(dataset))
        batch_size = 2
        
        for i in tqdm(range(0, max_samples, batch_size), desc=f"Epoch {epoch+1}"):
            try:
                # æ‰‹åŠ¨åˆ›å»ºæ‰¹æ¬¡
                batch_texts = []
                batch_poses = []
                
                for j in range(batch_size):
                    if i + j < max_samples:
                        sample = dataset[i + j]
                        batch_texts.append(sample['text'])
                        batch_poses.append(sample['pose_sequence'])
                
                if len(batch_texts) == 0:
                    continue
                
                # å¡«å……åˆ°ç›¸åŒé•¿åº¦
                max_len = max(pose.size(0) for pose in batch_poses)
                padded_poses = []
                
                for pose in batch_poses:
                    if pose.size(0) < max_len:
                        padding = torch.zeros(max_len - pose.size(0), pose.size(1))
                        padded_pose = torch.cat([pose, padding], dim=0)
                    else:
                        padded_pose = pose[:max_len]
                    padded_poses.append(padded_pose)
                
                target_poses = torch.stack(padded_poses).to(device)
                
                # å‰å‘ä¼ æ’­
                pred_poses, quality_scores = model(
                    texts=batch_texts,
                    language="ASL",
                    mode="mlsf",
                    max_length=target_poses.size(1)
                )
                
                # è®¡ç®—æŸå¤±
                loss = criterion(pred_poses, target_poses)
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                
                # ç»Ÿè®¡
                epoch_loss += loss.item()
                num_batches += 1
                
            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡ {i//batch_size} å¤±è´¥: {e}")
                continue
        
        avg_loss = epoch_loss / max(num_batches, 1)
        print(f"ğŸ“Š Epoch {epoch+1} å¹³å‡æŸå¤±: {avg_loss:.6f}")
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        checkpoint = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': avg_loss,
        }
        
        checkpoint_path = checkpoint_dir / f"epoch_{epoch+1}.pth"
        torch.save(checkpoint, checkpoint_path)
        print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
    
    print("\nâœ… å¿«é€Ÿè®­ç»ƒå®Œæˆï¼")
    
    # æ¨ç†æµ‹è¯•
    print("\nğŸ” æ¨ç†æµ‹è¯•...")
    model.eval()
    with torch.no_grad():
        try:
            test_texts = ["Hello world", "How are you"]
            test_poses, test_quality = model(
                texts=test_texts,
                language="ASL",
                mode="mlsf",
                max_length=50
            )
            print(f"âœ… æ¨ç†æˆåŠŸï¼")
            print(f"   è¾“å…¥æ–‡æœ¬: {test_texts}")
            print(f"   ç”Ÿæˆå§¿æ€å½¢çŠ¶: {test_poses.shape}")
            print(f"   è´¨é‡åˆ†æ•°: {test_quality.mean().item():.4f}")
        except Exception as e:
            print(f"âŒ æ¨ç†å¤±è´¥: {e}")
    
    print("\nğŸ‰ å¿«é€Ÿè®­ç»ƒéªŒè¯å®Œæˆï¼")
    print("å¦‚æœæ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸï¼Œæ‚¨å¯ä»¥å¼€å§‹å®Œæ•´è®­ç»ƒï¼š")
    print("python start_training.py --config configs/signllm_your_data_config.json")


if __name__ == "__main__":
    main() 