#!/usr/bin/env python3
"""
é›†æˆé…ç½®ç®¡ç†çš„è®­ç»ƒè„šæœ¬ - æ”¯æŒé…ç½®æ–‡ä»¶å’Œå‘½ä»¤è¡Œå‚æ•°
"""

import os
import sys
import json
import time
from pathlib import Path
from typing import List, Dict, Tuple

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from signllm_model import SignLLM
from data_processor import MultilingualSignDataset, collate_fn
from evaluation import SignLLMEvaluator
from config_manager import ConfigManager
from improved_signllm_train import PoseLoss, EarlyStopping, validate_model


def main():
    print("ğŸš€ SignLLM é…ç½®åŒ–è®­ç»ƒ")
    print("=" * 60)
    
    # è§£æé…ç½®
    config_manager = ConfigManager()
    config = config_manager.parse_args_and_config()
    
    print("ğŸ”§ è®­ç»ƒé…ç½®:")
    print(f"  æ¨¡å‹å¤§å°: {config.model_size}")
    print(f"  éšè—ç»´åº¦: {config.hidden_dim}")
    print(f"  æ‰¹æ¬¡å¤§å°: {config.batch_size}")
    print(f"  å­¦ä¹ ç‡: {config.learning_rate}")
    print(f"  è®­ç»ƒè½®æ•°: {config.num_epochs}")
    print(f"  è®¾å¤‡: {config.device_auto}")
    
    # å†…å­˜ä¼°ç®—
    memory_info = config.estimate_memory_usage()
    print(f"  ä¼°ç®—å†…å­˜: {memory_info['total_estimated_mb']:.1f} MB")
    
    # è®¾å¤‡
    device = torch.device(config.device_auto)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("checkpoints") / f"config_training_{config.model_size}"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜ä½¿ç”¨çš„é…ç½®
    config_manager.save_to_file(config, output_dir / "training_config.yaml")
    
    # TensorBoardæ—¥å¿—
    writer = SummaryWriter(log_dir=output_dir / "logs")
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ“¦ åˆ›å»ºæ¨¡å‹...")
    model = SignLLM(languages=["ASL"]).to(device)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ“Š å‚æ•°é‡: {total_params:,} ({total_params/1_000_000:.1f}M)")
    
    # æ•°æ®é›†
    print("ğŸ“š åŠ è½½æ•°æ®é›†...")
    train_dataset = MultilingualSignDataset(
        data_dirs={"ASL": "datasets/signllm_data_complete"},
        languages=["ASL"],
        split="dev",
        max_sequence_length=config.default_max_frames,
        pose_dim=config.pose_dim,
    )
    
    val_dataset = MultilingualSignDataset(
        data_dirs={"ASL": "datasets/signllm_data_complete"},
        languages=["ASL"],
        split="test",  # æš‚æ—¶ä½¿ç”¨devä½œä¸ºéªŒè¯é›†ï¼ˆå› ä¸ºtestä¸å­˜åœ¨ï¼‰
        max_sequence_length=config.default_max_frames,
        pose_dim=config.pose_dim,
    )
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config.batch_size, 
        shuffle=True,
        num_workers=config.num_workers, 
        pin_memory=config.pin_memory,
        collate_fn=collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=config.batch_size, 
        shuffle=False,
        num_workers=config.num_workers, 
        pin_memory=config.pin_memory,
        collate_fn=collate_fn
    )
    
    print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬: {len(train_dataset)}, éªŒè¯æ ·æœ¬: {len(val_dataset)}")
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±
    criterion = PoseLoss(
        alpha=config.loss_alpha, 
        beta=config.loss_beta, 
        gamma=config.loss_gamma
    )
    optimizer = optim.AdamW(
        model.parameters(), 
        lr=config.learning_rate, 
        weight_decay=config.weight_decay
    )
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5, verbose=True
    )
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = torch.amp.GradScaler(device.type) if config.mixed_precision else None
    
    # è¯„ä¼°å™¨å’Œæ—©åœ
    evaluator = SignLLMEvaluator()
    early_stopping = EarlyStopping(patience=config.patience)
    
    # è®­ç»ƒå¾ªç¯
    best_val_loss = float('inf')
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    
    for epoch in range(config.num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        epoch_losses = {'total': 0, 'mse': 0, 'motion': 0, 'consistency': 0}
        
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config.num_epochs}")
        for batch_idx, batch in enumerate(train_pbar):
            texts = batch["texts"]
            target_poses = batch["pose_sequences"].to(device)
            
            # å‰å‘ä¼ æ’­
            if config.mixed_precision and scaler:
                with torch.amp.autocast(device.type):
                    pred_poses, _ = model(
                        texts=texts,
                        language="ASL", 
                        mode="mlsf",
                        target_poses=target_poses
                    )
                    losses = criterion(pred_poses, target_poses)
                
                optimizer.zero_grad()
                scaler.scale(losses['total']).backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                scaler.step(optimizer)
                scaler.update()
            else:
                pred_poses, _ = model(
                    texts=texts,
                    language="ASL", 
                    mode="mlsf",
                    target_poses=target_poses
                )
                losses = criterion(pred_poses, target_poses)
                
                optimizer.zero_grad()
                losses['total'].backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
            
            # è®°å½•æŸå¤±
            for key in epoch_losses:
                epoch_losses[key] += losses[key].item()
            
            # æ›´æ–°è¿›åº¦æ¡
            current_loss = losses['total'].item()
            train_pbar.set_postfix({'loss': f'{current_loss:.4f}'})
            
            # è®°å½•åˆ°TensorBoard
            step = epoch * len(train_loader) + batch_idx
            writer.add_scalar('Train/Loss', current_loss, step)
        
        # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
        avg_train_losses = {k: v / len(train_loader) for k, v in epoch_losses.items()}
        
        # éªŒè¯é˜¶æ®µ
        val_metrics = validate_model(model, val_loader, criterion, evaluator, device)
        val_loss = val_metrics['total']
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(val_loss)
        
        # è®°å½•åˆ°TensorBoard
        for key, value in avg_train_losses.items():
            writer.add_scalar(f'Train/{key.capitalize()}Loss', value, epoch)
        for key, value in val_metrics.items():
            writer.add_scalar(f'Val/{key.capitalize()}', value, epoch)
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š Epoch {epoch+1}/{config.num_epochs}:")
        print(f"  è®­ç»ƒæŸå¤±: {avg_train_losses['total']:.6f}")
        print(f"  éªŒè¯æŸå¤±: {val_loss:.6f}")
        print(f"  DTWåˆ†æ•°: {val_metrics.get('dtw_score', 0):.4f}")
        print(f"  å§¿æ€ç›¸ä¼¼åº¦: {val_metrics.get('pose_similarity', 0):.4f}")
        print(f"  å½“å‰å­¦ä¹ ç‡: {scheduler.optimizer.param_groups[0]['lr']:.2e}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'config': config.to_dict(),
                'val_loss': val_loss,
                'val_metrics': val_metrics
            }
            torch.save(checkpoint, output_dir / 'best_model.pth')
            print("ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹")
        
        # å®šæœŸä¿å­˜checkpoint
        if (epoch + 1) % 10 == 0:
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'config': config.to_dict(),
                'val_loss': val_loss,
                'val_metrics': val_metrics
            }
            torch.save(checkpoint, output_dir / f'checkpoint_epoch_{epoch+1}.pth')
        
        # æ—©åœæ£€æŸ¥
        if early_stopping(val_loss):
            print(f"ğŸ›‘ æ—©åœè§¦å‘ (epoch {epoch+1})")
            break
    
    writer.close()
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {output_dir}")
    
    # æœ€ç»ˆæµ‹è¯•
    print("\nğŸ” æœ€ç»ˆæ¨ç†æµ‹è¯•...")
    model.eval()
    with torch.no_grad():
        test_texts = ["Hello world", "How are you?"]
        test_poses, _ = model(texts=test_texts, language="ASL", mode="mlsf")
        print(f"âœ… æ¨ç†æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {test_poses.shape}")


if __name__ == "__main__":
    main() 