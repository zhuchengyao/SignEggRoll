#!/usr/bin/env python3
"""
æœ€å°åŒ–SignLLMè®­ç»ƒè„šæœ¬ - è§£å†³æ•°æ®æ ¼å¼é—®é¢˜
"""

import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from pathlib import Path
import numpy as np
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from signllm_model import SignLLM, ModelConfig, CONFIG
from data_processor import MultilingualSignDataset


def main():
    print("ğŸš€ æœ€å°åŒ–SignLLMè®­ç»ƒ")
    print("=" * 50)
    
    # è®¾ç½®æ¨¡å‹å¤§å° - åªéœ€è¦æ”¹è¿™é‡Œï¼
    # å¯é€‰: "tiny", "small", "medium", "large"
    MODEL_SIZE = "tiny"  # ä½¿ç”¨æœ€å°çš„æ¨¡å‹
    
    # æ›´æ–°å…¨å±€é…ç½®
    global CONFIG
    CONFIG.__init__(MODEL_SIZE)
    
    # è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºç®€åŒ–æ¨¡å‹
    print("ğŸ“¦ åˆ›å»ºæ¨¡å‹...")
    model = SignLLM(languages=["ASL"]).to(device)
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ“Š å®é™…æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1_000_000:.1f}M)")
    
    # åˆ›å»ºæ•°æ®é›†
    print("ğŸ“š åˆ›å»ºæ•°æ®é›†...")
    dataset = MultilingualSignDataset(
        data_dirs={"ASL": "datasets/signllm_data_complete"},
        languages=["ASL"],
        split="dev",
        max_sequence_length=256,
        pose_dim=CONFIG.pose_dim
    )
    
    print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)} æ ·æœ¬")
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(model.parameters(), lr=1e-4)
    criterion = nn.MSELoss()
    
    # è®­ç»ƒå¾ªç¯
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    model.train()
    epoch_num = 10
    
    for epoch in range(epoch_num):
        print(f"\nğŸ“… Epoch {epoch+1}/{epoch_num}")
        epoch_loss = 0
        num_batches = 0
        
        # æ‰‹åŠ¨æ‰¹å¤„ç†
        batch_size = 2
        for i in tqdm(range(0, len(dataset), batch_size), desc=f"Epoch {epoch+1}"):
            try:
                # æ‰‹åŠ¨åˆ›å»ºæ‰¹æ¬¡
                batch_texts = []
                batch_poses = []
                
                for j in range(batch_size):
                    if i + j < len(dataset):
                        sample = dataset[i + j]
                        batch_texts.append(sample['text'])
                        batch_poses.append(sample['pose_sequence'])
                
                if len(batch_texts) == 0:
                    continue
                
                # è½¬æ¢ä¸ºå¼ é‡
                target_poses = torch.stack(batch_poses).to(device)
                
                # å‰å‘ä¼ æ’­
                pred_poses, quality_scores = model(
                    texts=batch_texts,
                    language="ASL",
                    mode="mlsf",
                    max_length=target_poses.size(1)
                )
                
                # è®¡ç®—æŸå¤±
                loss = criterion(pred_poses, target_poses)
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                
                # ç»Ÿè®¡
                epoch_loss += loss.item()
                num_batches += 1
                
            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡ {i//batch_size} å¤±è´¥: {e}")
                continue
        
        avg_loss = epoch_loss / max(num_batches, 1)
        print(f"ğŸ“Š Epoch {epoch+1} å¹³å‡æŸå¤±: {avg_loss:.6f}")
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % 1 == 0:
            checkpoint_dir = Path("checkpoints/eggroll_train")
            checkpoint_dir.mkdir(parents=True, exist_ok=True)
            
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': avg_loss,
            }
            
            checkpoint_path = checkpoint_dir / f"epoch_{epoch+1}.pth"
            torch.save(checkpoint, checkpoint_path)
            print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
    
    print("\nâœ… è®­ç»ƒå®Œæˆï¼")
    
    # ç®€å•æ¨ç†æµ‹è¯•
    print("\nğŸ” æ¨ç†æµ‹è¯•...")
    model.eval()
    with torch.no_grad():
        test_texts = ["Hello world"]
        test_poses, test_quality = model(
            texts=test_texts,
            language="ASL",
            mode="mlsf"
        )
        print(f"âœ… æ¨ç†æˆåŠŸï¼ç”Ÿæˆå§¿æ€å½¢çŠ¶: {test_poses.shape}")
        print(f"ğŸ“ ç”Ÿæˆå¸§æ•°: {test_poses.shape[1]}")


if __name__ == "__main__":
    main() 