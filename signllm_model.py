"""
SignLLM: Sign Language Production Large Language Models
å®Œæ•´çš„æ¨¡å‹å®ç°ï¼ŒåŒ…å«MLSFå’ŒPrompt2LangGlossæ¨¡å¼
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel
from typing import Dict, List, Optional, Tuple, Union
import math
import numpy as np


class ModelConfig:
    """ç»Ÿä¸€çš„æ¨¡å‹é…ç½®ç±» - æ‰€æœ‰å‚æ•°éƒ½åœ¨è¿™é‡Œç®¡ç†"""
    def __init__(self, model_size: str = "small"):
        """
        Args:
            model_size: æ¨¡å‹å¤§å° ("tiny", "small", "medium", "large")
        """
        self.model_size = model_size
        
        # æ ¹æ®æ¨¡å‹å¤§å°è®¾ç½®æ‰€æœ‰å‚æ•°
        if model_size == "tiny":
            self.hidden_dim = 256
            self.num_layers = 2
            self.num_heads = 4
            self.ff_multiplier = 2
            self.gloss_vocab_size = 1000
        elif model_size == "small":
            self.hidden_dim = 512
            self.num_layers = 4
            self.num_heads = 8
            self.ff_multiplier = 2
            self.gloss_vocab_size = 2000
        elif model_size == "medium":
            self.hidden_dim = 768
            self.num_layers = 6
            self.num_heads = 12
            self.ff_multiplier = 3
            self.gloss_vocab_size = 5000
        elif model_size == "large":
            self.hidden_dim = 1024
            self.num_layers = 8
            self.num_heads = 16
            self.ff_multiplier = 4
            self.gloss_vocab_size = 10000
        else:
            raise ValueError(f"Unknown model size: {model_size}")
        
        # è®¡ç®—æ´¾ç”Ÿå‚æ•°
        self.dim_feedforward = self.hidden_dim * self.ff_multiplier
        
        # å›ºå®šå‚æ•°
        self.pose_dim = 150
        self.dropout = 0.1
        self.max_sequence_length = 512
        self.bert_model = "bert-base-multilingual-cased"
        self.num_priorities = 8
        self.num_languages = 8
        
        # å¸§æ•°æ§åˆ¶å‚æ•°
        self.default_max_frames = 256    # é»˜è®¤ç”Ÿæˆå¸§æ•°
        self.min_frames = 30            # æœ€å°å¸§æ•°
        self.max_frames = 500           # æœ€å¤§å¸§æ•°
        
    def print_config(self):
        """æ‰“å°é…ç½®ä¿¡æ¯"""
        print(f"ğŸ”§ æ¨¡å‹é…ç½® ({self.model_size}):")
        print(f"  Hidden Dim: {self.hidden_dim}")
        print(f"  Layers: {self.num_layers}")
        print(f"  Attention Heads: {self.num_heads}")
        print(f"  FF Dim: {self.dim_feedforward}")
        print(f"  Gloss Vocab: {self.gloss_vocab_size}")
        print(f"  Pose Dim: {self.pose_dim}")
        print(f"  é»˜è®¤ç”Ÿæˆå¸§æ•°: {self.default_max_frames}")
        print(f"  å¸§æ•°èŒƒå›´: {self.min_frames}-{self.max_frames}")
        
    def estimate_params(self):
        """ä¼°ç®—æ¨¡å‹å‚æ•°æ•°é‡"""
        # è¿™æ˜¯ä¸€ä¸ªç²—ç•¥ä¼°ç®—
        bert_params = 110_000_000  # BERT baseå‚æ•°
        projection_params = 768 * self.hidden_dim
        
        # Transformerå±‚å‚æ•° (ç²—ç•¥ä¼°ç®—)
        attention_params = 4 * self.hidden_dim * self.hidden_dim * self.num_layers
        ff_params = 2 * self.hidden_dim * self.dim_feedforward * self.num_layers
        
        # å…¶ä»–ç»„ä»¶
        embedding_params = self.gloss_vocab_size * self.hidden_dim
        other_params = self.hidden_dim * 1000  # å…¶ä»–å°ç»„ä»¶
        
        total = bert_params + projection_params + attention_params + ff_params + embedding_params + other_params
        return total


# å…¨å±€é…ç½®å®ä¾‹
CONFIG = ModelConfig("small")  # é»˜è®¤ä½¿ç”¨smallæ¨¡å‹


class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    def __init__(self, d_model: int, max_len: int = 5000):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        return x + self.pe[:x.size(0), :]


class PriorityLearningChannel(nn.Module):
    """Priority Learning Channel (PLC) - å¼ºåŒ–å­¦ä¹ æ¨¡å—"""
    def __init__(self):
        super().__init__()
        
        # ä¼˜å…ˆçº§æ³¨æ„åŠ›æœºåˆ¶
        self.priority_attention = nn.MultiheadAttention(
            embed_dim=CONFIG.hidden_dim,
            num_heads=CONFIG.num_heads,
            dropout=CONFIG.dropout
        )
        
        # ä¼˜å…ˆçº§æƒé‡ç½‘ç»œ
        self.priority_weights = nn.Sequential(
            nn.Linear(CONFIG.hidden_dim, CONFIG.hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(CONFIG.hidden_dim // 2, CONFIG.num_priorities),
            nn.Softmax(dim=-1)
        )
        
        # è´¨é‡è¯„ä¼°ç½‘ç»œ
        self.quality_estimator = nn.Sequential(
            nn.Linear(CONFIG.hidden_dim, CONFIG.hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(CONFIG.hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            x: [batch_size, seq_len, hidden_dim]
            mask: [batch_size, seq_len]
        Returns:
            enhanced_x: å¢å¼ºåçš„ç‰¹å¾
            quality_scores: è´¨é‡åˆ†æ•°
        """
        batch_size, seq_len, hidden_dim = x.shape
        
        # ä¼˜å…ˆçº§æ³¨æ„åŠ›
        attn_output, _ = self.priority_attention(x, x, x, key_padding_mask=mask)
        
        # è®¡ç®—ä¼˜å…ˆçº§æƒé‡
        priority_weights = self.priority_weights(attn_output)  # [batch_size, seq_len, num_priorities]
        
        # è´¨é‡è¯„ä¼°
        quality_scores = self.quality_estimator(attn_output).squeeze(-1)  # [batch_size, seq_len]
        
        # åŠ æƒèåˆ
        enhanced_x = attn_output * quality_scores.unsqueeze(-1)
        
        return enhanced_x, quality_scores


class TextEncoder(nn.Module):
    """æ–‡æœ¬ç¼–ç å™¨"""
    def __init__(self):
        super().__init__()
        self.tokenizer = AutoTokenizer.from_pretrained(CONFIG.bert_model)
        self.encoder = AutoModel.from_pretrained(CONFIG.bert_model)
        self.projection = nn.Linear(self.encoder.config.hidden_size, CONFIG.hidden_dim)
        self.layer_norm = nn.LayerNorm(CONFIG.hidden_dim)
        
    def forward(self, texts: List[str], device: torch.device) -> torch.Tensor:
        """
        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨
            device: è®¾å¤‡
        Returns:
            encoded_texts: [batch_size, seq_len, hidden_dim]
        """
        # åˆ†è¯å’Œç¼–ç 
        inputs = self.tokenizer(
            texts, 
            return_tensors="pt", 
            padding=True, 
            truncation=True, 
            max_length=512
        ).to(device)
        
        # è·å–æ–‡æœ¬ç‰¹å¾
        outputs = self.encoder(**inputs)
        text_features = outputs.last_hidden_state  # [batch_size, seq_len, bert_hidden]
        
        # æŠ•å½±åˆ°ç›®æ ‡ç»´åº¦
        projected = self.projection(text_features)
        return self.layer_norm(projected)


class GlossEncoder(nn.Module):
    """Glossç¼–ç å™¨"""
    def __init__(self):
        super().__init__()
        self.embedding = nn.Embedding(CONFIG.gloss_vocab_size, CONFIG.hidden_dim)
        self.pos_encoding = PositionalEncoding(CONFIG.hidden_dim, CONFIG.max_sequence_length)
        self.layer_norm = nn.LayerNorm(CONFIG.hidden_dim)
        
    def forward(self, gloss_ids: torch.Tensor) -> torch.Tensor:
        """
        Args:
            gloss_ids: [batch_size, seq_len]
        Returns:
            encoded_gloss: [batch_size, seq_len, hidden_dim]
        """
        embedded = self.embedding(gloss_ids)
        positioned = self.pos_encoding(embedded)
        return self.layer_norm(positioned)


class PoseDecoder(nn.Module):
    """å§¿æ€è§£ç å™¨"""
    def __init__(self):
        super().__init__()
        
        # Transformerè§£ç å™¨å±‚
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=CONFIG.hidden_dim,
            nhead=CONFIG.num_heads,
            dim_feedforward=CONFIG.dim_feedforward,
            dropout=CONFIG.dropout,
            activation="gelu"
        )
        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, CONFIG.num_layers)
        
        # å§¿æ€æŠ•å½±å±‚
        self.pose_projection = nn.Sequential(
            nn.Linear(CONFIG.hidden_dim, CONFIG.hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(CONFIG.dropout),
            nn.Linear(CONFIG.hidden_dim // 2, CONFIG.pose_dim)
        )
        
        # ä½ç½®ç¼–ç 
        self.pos_encoding = PositionalEncoding(CONFIG.hidden_dim)
        
    def forward(self, memory: torch.Tensor, tgt: torch.Tensor, 
                tgt_mask: Optional[torch.Tensor] = None,
                memory_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Args:
            memory: ç¼–ç å™¨è¾“å‡º [seq_len, batch_size, hidden_dim]
            tgt: ç›®æ ‡åºåˆ— [tgt_len, batch_size, hidden_dim]
            tgt_mask: ç›®æ ‡æ©ç 
            memory_mask: è®°å¿†æ©ç 
        Returns:
            poses: [batch_size, tgt_len, pose_dim]
        """
        # æ·»åŠ ä½ç½®ç¼–ç 
        tgt = self.pos_encoding(tgt)
        
        # Transformerè§£ç 
        decoded = self.transformer_decoder(
            tgt, memory, 
            tgt_mask=tgt_mask,
            memory_key_padding_mask=memory_mask
        )
        
        # è½¬æ¢ç»´åº¦å¹¶æŠ•å½±åˆ°å§¿æ€ç©ºé—´
        decoded = decoded.transpose(0, 1)  # [batch_size, tgt_len, hidden_dim]
        poses = self.pose_projection(decoded)
        
        return poses


class MLSFMode(nn.Module):
    """Multi-Language Switching Framework (MLSF) æ¨¡å¼"""
    def __init__(self, languages: List[str]):
        super().__init__()
        self.languages = languages
        
        # æ¯ç§è¯­è¨€çš„æ–‡æœ¬ç¼–ç å™¨
        self.text_encoders = nn.ModuleDict({
            lang: TextEncoder() for lang in languages
        })
        
        # æ¯ç§è¯­è¨€çš„å§¿æ€è§£ç å™¨
        self.pose_decoders = nn.ModuleDict({
            lang: PoseDecoder() for lang in languages
        })
        
        # Priority Learning Channel
        self.plc = PriorityLearningChannel()
        
    def forward(self, texts: List[str], language: str, max_length: int = None) -> torch.Tensor:
        """
        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨
            language: ç›®æ ‡è¯­è¨€
            max_length: æœ€å¤§ç”Ÿæˆé•¿åº¦ (Noneæ—¶ä½¿ç”¨é»˜è®¤å€¼)
        Returns:
            poses: [batch_size, max_length, pose_dim]
        """
        if max_length is None:
            max_length = CONFIG.default_max_frames
            
        # é™åˆ¶å¸§æ•°èŒƒå›´
        max_length = max(CONFIG.min_frames, min(max_length, CONFIG.max_frames))
        
        device = next(self.parameters()).device
        batch_size = len(texts)
        
        # æ–‡æœ¬ç¼–ç 
        text_features = self.text_encoders[language](texts, device)
        
        # PLCå¢å¼º
        enhanced_features, quality_scores = self.plc(text_features)
        
        # å‡†å¤‡è§£ç å™¨è¾“å…¥
        memory = enhanced_features.transpose(0, 1)  # [seq_len, batch_size, hidden_dim]
        
        # åˆå§‹åŒ–ç›®æ ‡åºåˆ—ï¼ˆèµ·å§‹tokenï¼‰
        tgt = torch.zeros(1, batch_size, CONFIG.hidden_dim, device=device)
        
        # è‡ªå›å½’ç”Ÿæˆ
        poses = []
        for _ in range(max_length):
            # è§£ç ä¸€æ­¥
            decoded = self.pose_decoders[language](memory, tgt)
            pose_step = decoded[:, -1:, :]  # å–æœ€åä¸€æ­¥
            poses.append(pose_step)
            
            # æ›´æ–°ç›®æ ‡åºåˆ— - éœ€è¦å°†pose_stepæŠ•å½±å›hidden_dim
            # åˆ›å»ºä¸€ä¸ªæŠ•å½±å±‚å°†pose_dimæ˜ å°„å›hidden_dim
            if not hasattr(self, 'pose_to_hidden'):
                self.pose_to_hidden = nn.Linear(CONFIG.pose_dim, CONFIG.hidden_dim).to(device)
            
            hidden_step = self.pose_to_hidden(pose_step).transpose(0, 1)  # [1, batch_size, hidden_dim]
            tgt = torch.cat([tgt, hidden_step], dim=0)
        
        return torch.cat(poses, dim=1), quality_scores


class Prompt2LangGlossMode(nn.Module):
    """Prompt2LangGlossæ¨¡å¼"""
    def __init__(self):
        super().__init__()
        
        # æ–‡æœ¬ç¼–ç å™¨
        self.text_encoder = TextEncoder()
        
        # Glossç”Ÿæˆå™¨
        self.gloss_generator = nn.Sequential(
            nn.Linear(CONFIG.hidden_dim, CONFIG.hidden_dim),
            nn.ReLU(),
            nn.Dropout(CONFIG.dropout),
            nn.Linear(CONFIG.hidden_dim, CONFIG.gloss_vocab_size)
        )
        
        # Glossç¼–ç å™¨
        self.gloss_encoder = GlossEncoder()
        
        # å§¿æ€è§£ç å™¨
        self.pose_decoder = PoseDecoder()
        
        # Priority Learning Channel
        self.plc = PriorityLearningChannel()
        
        # è¯­è¨€æ ‡è®°åµŒå…¥
        self.language_embedding = nn.Embedding(CONFIG.num_languages, CONFIG.hidden_dim)
        
    def forward(self, texts: List[str], language_ids: torch.Tensor, 
                max_gloss_length: int = 128, max_pose_length: int = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨
            language_ids: è¯­è¨€ID [batch_size]
            max_gloss_length: æœ€å¤§glossé•¿åº¦
            max_pose_length: æœ€å¤§å§¿æ€é•¿åº¦ (Noneæ—¶ä½¿ç”¨é»˜è®¤å€¼)
        Returns:
            poses: [batch_size, max_pose_length, pose_dim]
            gloss_logits: [batch_size, max_gloss_length, gloss_vocab_size]
        """
        if max_pose_length is None:
            max_pose_length = CONFIG.default_max_frames
            
        # é™åˆ¶å¸§æ•°èŒƒå›´
        max_pose_length = max(CONFIG.min_frames, min(max_pose_length, CONFIG.max_frames))
        
        device = next(self.parameters()).device
        batch_size = len(texts)
        
        # ç¡®ä¿language_idsåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        language_ids = language_ids.to(device)
        
        # æ–‡æœ¬ç¼–ç 
        text_features = self.text_encoder(texts, device)
        
        # æ·»åŠ è¯­è¨€æ ‡è®°
        lang_embeds = self.language_embedding(language_ids).unsqueeze(1)
        text_features = text_features + lang_embeds
        
        # PLCå¢å¼º
        enhanced_features, quality_scores = self.plc(text_features)
        
        # ç”ŸæˆGloss
        gloss_logits = self.gloss_generator(enhanced_features)
        gloss_ids = torch.argmax(gloss_logits, dim=-1)
        
        # Glossç¼–ç 
        gloss_features = self.gloss_encoder(gloss_ids)
        
        # å§¿æ€è§£ç 
        memory = gloss_features.transpose(0, 1)
        tgt = torch.zeros(1, batch_size, CONFIG.hidden_dim, device=device)
        
        poses = []
        for _ in range(max_pose_length):
            decoded = self.pose_decoder(memory, tgt)
            pose_step = decoded[:, -1:, :]
            poses.append(pose_step)
            
            # æ›´æ–°ç›®æ ‡åºåˆ— - éœ€è¦å°†pose_stepæŠ•å½±å›hidden_dim
            if not hasattr(self, 'pose_to_hidden_p2lg'):
                self.pose_to_hidden_p2lg = nn.Linear(CONFIG.pose_dim, CONFIG.hidden_dim).to(device)
            
            hidden_step = self.pose_to_hidden_p2lg(pose_step).transpose(0, 1)
            tgt = torch.cat([tgt, hidden_step], dim=0)
        
        return torch.cat(poses, dim=1), gloss_logits, quality_scores


class SignLLM(nn.Module):
    """SignLLMä¸»æ¨¡å‹"""
    def __init__(self, languages: List[str] = ["ASL"]):
        super().__init__()
        self.languages = languages
        self.language_to_id = {lang: i for i, lang in enumerate(languages)}
        
        # æ‰“å°æ¨¡å‹é…ç½®
        CONFIG.print_config()
        estimated_params = CONFIG.estimate_params()
        print(f"  ä¼°è®¡å‚æ•°é‡: {estimated_params:,} ({estimated_params/1_000_000:.1f}M)")
        
        # MLSFæ¨¡å¼
        self.mlsf_mode = MLSFMode(languages)
        
        # Prompt2LangGlossæ¨¡å¼
        self.prompt2langgloss_mode = Prompt2LangGlossMode()
        
    def forward(self, texts: List[str], language: str, mode: str = "mlsf", **kwargs):
        """
        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨
            language: ç›®æ ‡è¯­è¨€
            mode: æ¨¡å¼ ("mlsf" æˆ– "prompt2langgloss")
        Returns:
            æ ¹æ®æ¨¡å¼è¿”å›ä¸åŒçš„è¾“å‡º
        """
        if mode == "mlsf":
            return self.mlsf_mode(texts, language, **kwargs)
        elif mode == "prompt2langgloss":
            language_ids = torch.tensor([self.language_to_id[language]] * len(texts))
            if torch.cuda.is_available():
                language_ids = language_ids.cuda()
            return self.prompt2langgloss_mode(texts, language_ids, **kwargs)
        else:
            raise ValueError(f"Unknown mode: {mode}")


class RLLoss(nn.Module):
    """å¼ºåŒ–å­¦ä¹ æŸå¤±å‡½æ•°"""
    def __init__(self, alpha: float = 0.1, beta: float = 0.1):
        super().__init__()
        self.alpha = alpha  # è´¨é‡æƒé‡
        self.beta = beta   # å¤šæ ·æ€§æƒé‡
        self.mse_loss = nn.MSELoss(reduction='none')
        
    def forward(self, pred_poses: torch.Tensor, target_poses: torch.Tensor, 
                quality_scores: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Args:
            pred_poses: é¢„æµ‹å§¿æ€ [batch_size, seq_len, pose_dim]
            target_poses: ç›®æ ‡å§¿æ€ [batch_size, seq_len, pose_dim]
            quality_scores: è´¨é‡åˆ†æ•° [batch_size, seq_len]
            mask: æ©ç  [batch_size, seq_len]
        Returns:
            loss: æ€»æŸå¤±
        """
        # åŸºç¡€MSEæŸå¤±
        mse_loss = self.mse_loss(pred_poses, target_poses).mean(dim=-1)  # [batch_size, seq_len]
        
        # è´¨é‡åŠ æƒæŸå¤±
        quality_weighted_loss = mse_loss * (1.0 + self.alpha * (1.0 - quality_scores))
        
        # å¤šæ ·æ€§æ­£åˆ™åŒ–
        diversity_loss = -self.beta * torch.var(quality_scores, dim=1).mean()
        
        # åº”ç”¨æ©ç 
        if mask is not None:
            quality_weighted_loss = quality_weighted_loss * mask
            quality_weighted_loss = quality_weighted_loss.sum() / mask.sum()
        else:
            quality_weighted_loss = quality_weighted_loss.mean()
        
        return quality_weighted_loss + diversity_loss


def create_causal_mask(size: int) -> torch.Tensor:
    """åˆ›å»ºå› æœæ©ç """
    mask = torch.triu(torch.ones(size, size), diagonal=1).bool()
    return mask


def create_padding_mask(lengths: torch.Tensor, max_len: int) -> torch.Tensor:
    """åˆ›å»ºå¡«å……æ©ç """
    batch_size = lengths.size(0)
    mask = torch.arange(max_len).expand(batch_size, max_len) >= lengths.unsqueeze(1)
    return mask


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    model = SignLLM()
    texts = ["Hello world", "How are you?"]
    
    # æµ‹è¯•MLSFæ¨¡å¼
    poses_mlsf, quality_scores = model(texts, "ASL", mode="mlsf", max_length=100)
    print(f"MLSFè¾“å‡ºå½¢çŠ¶: {poses_mlsf.shape}")
    
    # æµ‹è¯•Prompt2LangGlossæ¨¡å¼
    poses_p2lg, gloss_logits, quality_scores = model(texts, "ASL", mode="prompt2langgloss")
    print(f"Prompt2LangGlosså§¿æ€è¾“å‡ºå½¢çŠ¶: {poses_p2lg.shape}")
    print(f"Glossè¾“å‡ºå½¢çŠ¶: {gloss_logits.shape}") 