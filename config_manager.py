#!/usr/bin/env python3
"""
é…ç½®ç®¡ç†ç³»ç»Ÿ - æ”¯æŒYAML/JSONé…ç½®æ–‡ä»¶å’Œå‘½ä»¤è¡Œå‚æ•°
"""

import yaml
import json
import argparse
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass, asdict
import logging

logger = logging.getLogger(__name__)


@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½® - ä½¿ç”¨dataclassè‡ªåŠ¨ç”Ÿæˆ"""
    
    # æ¨¡å‹è§„æ¨¡
    model_size: str = "small"
    
    # ç½‘ç»œæ¶æ„
    hidden_dim: int = 512
    num_layers: int = 4
    num_heads: int = 8
    ff_multiplier: int = 2
    dropout: float = 0.1
    
    # æ•°æ®ç»´åº¦
    pose_dim: int = 150
    gloss_vocab_size: int = 2000
    max_sequence_length: int = 512
    
    # è®­ç»ƒå‚æ•°
    batch_size: int = 4
    learning_rate: float = 1e-4
    weight_decay: float = 0.01
    num_epochs: int = 50
    patience: int = 10
    
    # æ•°æ®è®¾ç½®
    min_frames: int = 30
    max_frames: int = 500
    default_max_frames: int = 256
    
    # å¤šè¯­è¨€è®¾ç½®
    num_priorities: int = 8
    num_languages: int = 8
    bert_model: str = "bert-base-multilingual-cased"
    
    # æŸå¤±å‡½æ•°æƒé‡
    loss_alpha: float = 1.0  # MSEæƒé‡
    loss_beta: float = 0.5   # è¿åŠ¨å¹³æ»‘åº¦æƒé‡
    loss_gamma: float = 0.3  # å§¿æ€ä¸€è‡´æ€§æƒé‡
    
    # æ•°æ®å¢å¼º
    use_data_augmentation: bool = True
    augmentation_noise_std: float = 0.01
    augmentation_speed_factors: list = None
    
    # è®¾å¤‡å’Œæ€§èƒ½
    device: str = "auto"  # auto, cpu, cuda
    mixed_precision: bool = True
    num_workers: int = 2
    pin_memory: bool = True
    
    def __post_init__(self):
        """åå¤„ç†ï¼šæ ¹æ®model_sizeè‡ªåŠ¨è®¾ç½®å‚æ•°"""
        if self.augmentation_speed_factors is None:
            self.augmentation_speed_factors = [0.8, 1.2]
            
        # æ ¹æ®æ¨¡å‹å¤§å°è‡ªåŠ¨è°ƒæ•´å‚æ•°
        size_configs = {
            "tiny": {
                "hidden_dim": 256,
                "num_layers": 2,
                "num_heads": 4,
                "ff_multiplier": 2,
                "gloss_vocab_size": 1000,
                "batch_size": 8
            },
            "small": {
                "hidden_dim": 512,
                "num_layers": 4,
                "num_heads": 8,
                "ff_multiplier": 2,
                "gloss_vocab_size": 2000,
                "batch_size": 4
            },
            "medium": {
                "hidden_dim": 768,
                "num_layers": 6,
                "num_heads": 12,
                "ff_multiplier": 3,
                "gloss_vocab_size": 5000,
                "batch_size": 2
            },
            "large": {
                "hidden_dim": 1024,
                "num_layers": 8,
                "num_heads": 16,
                "ff_multiplier": 4,
                "gloss_vocab_size": 10000,
                "batch_size": 1
            }
        }
        
        if self.model_size in size_configs:
            for key, value in size_configs[self.model_size].items():
                if not hasattr(self, '_manually_set') or key not in getattr(self, '_manually_set', set()):
                    setattr(self, key, value)
        
        # è®¡ç®—è¡ç”Ÿå‚æ•°
        self.dim_feedforward = self.hidden_dim * self.ff_multiplier
    
    @property
    def device_auto(self) -> str:
        """è‡ªåŠ¨æ£€æµ‹è®¾å¤‡"""
        if self.device == "auto":
            import torch
            return "cuda" if torch.cuda.is_available() else "cpu"
        return self.device
    
    def estimate_memory_usage(self) -> Dict[str, float]:
        """ä¼°ç®—å†…å­˜ä½¿ç”¨"""
        # ç®€åŒ–çš„å†…å­˜ä¼°ç®—ï¼ˆMBï¼‰
        param_memory = (self.hidden_dim ** 2 * self.num_layers * 4) / (1024 ** 2)  # å‚æ•°å†…å­˜
        batch_memory = (self.batch_size * self.max_sequence_length * self.hidden_dim * 4) / (1024 ** 2)  # æ‰¹æ¬¡å†…å­˜
        
        return {
            "parameter_memory_mb": param_memory,
            "batch_memory_mb": batch_memory,
            "total_estimated_mb": param_memory + batch_memory * 2  # æ¢¯åº¦å ç”¨é¢å¤–å†…å­˜
        }
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, config_dict: Dict[str, Any]) -> 'ModelConfig':
        """ä»å­—å…¸åˆ›å»ºé…ç½®"""
        return cls(**config_dict)


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        self.config_paths = []
    
    def load_from_file(self, config_path: str) -> ModelConfig:
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        config_path = Path(config_path)
        
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŠ è½½æ–¹å¼
        if config_path.suffix.lower() == '.yaml' or config_path.suffix.lower() == '.yml':
            with open(config_path, 'r', encoding='utf-8') as f:
                config_dict = yaml.safe_load(f)
        elif config_path.suffix.lower() == '.json':
            with open(config_path, 'r', encoding='utf-8') as f:
                config_dict = json.load(f)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é…ç½®æ–‡ä»¶æ ¼å¼: {config_path.suffix}")
        
        logger.info(f"ä» {config_path} åŠ è½½é…ç½®")
        return ModelConfig.from_dict(config_dict)
    
    def save_to_file(self, config: ModelConfig, config_path: str):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        config_path = Path(config_path)
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        config_dict = config.to_dict()
        
        if config_path.suffix.lower() in ['.yaml', '.yml']:
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config_dict, f, default_flow_style=False, allow_unicode=True)
        elif config_path.suffix.lower() == '.json':
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config_dict, f, indent=2, ensure_ascii=False)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„é…ç½®æ–‡ä»¶æ ¼å¼: {config_path.suffix}")
        
        logger.info(f"é…ç½®å·²ä¿å­˜åˆ° {config_path}")
    
    def create_argparser(self) -> argparse.ArgumentParser:
        """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
        parser = argparse.ArgumentParser(description="SignLLM è®­ç»ƒé…ç½®")
        
        # åŸºç¡€å‚æ•°
        parser.add_argument("--config", type=str, help="é…ç½®æ–‡ä»¶è·¯å¾„")
        parser.add_argument("--model-size", type=str, choices=["tiny", "small", "medium", "large"],
                          default="small", help="æ¨¡å‹å¤§å°")
        
        # è®­ç»ƒå‚æ•°
        parser.add_argument("--batch-size", type=int, help="æ‰¹æ¬¡å¤§å°")
        parser.add_argument("--learning-rate", type=float, help="å­¦ä¹ ç‡")
        parser.add_argument("--num-epochs", type=int, help="è®­ç»ƒè½®æ•°")
        parser.add_argument("--patience", type=int, help="æ—©åœè€å¿ƒå€¼")
        
        # æ•°æ®å‚æ•°
        parser.add_argument("--data-dir", type=str, help="æ•°æ®ç›®å½•")
        parser.add_argument("--max-frames", type=int, help="æœ€å¤§å¸§æ•°")
        
        # è®¾å¤‡å‚æ•°
        parser.add_argument("--device", type=str, choices=["auto", "cpu", "cuda"], 
                          default="auto", help="è®¡ç®—è®¾å¤‡")
        parser.add_argument("--no-mixed-precision", action="store_true", 
                          help="ç¦ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
        
        # è¾“å‡ºå‚æ•°
        parser.add_argument("--output-dir", type=str, default="outputs", help="è¾“å‡ºç›®å½•")
        parser.add_argument("--save-config", type=str, help="ä¿å­˜å½“å‰é…ç½®åˆ°æ–‡ä»¶")
        
        return parser
    
    def parse_args_and_config(self, args=None) -> ModelConfig:
        """è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶åˆå¹¶é…ç½®"""
        parser = self.create_argparser()
        parsed_args = parser.parse_args(args)
        
        # é¦–å…ˆåŠ è½½åŸºç¡€é…ç½®
        if parsed_args.config:
            config = self.load_from_file(parsed_args.config)
        else:
            config = ModelConfig()
        
        # ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
        config._manually_set = set()
        
        for arg_name, arg_value in vars(parsed_args).items():
            if arg_value is not None and arg_name != 'config' and arg_name != 'save_config':
                # è½¬æ¢å‚æ•°åç§°æ ¼å¼
                config_name = arg_name.replace('-', '_')
                if config_name == 'no_mixed_precision':
                    config.mixed_precision = False
                    config._manually_set.add('mixed_precision')
                elif hasattr(config, config_name):
                    setattr(config, config_name, arg_value)
                    config._manually_set.add(config_name)
        
        # é‡æ–°åˆå§‹åŒ–ä»¥åº”ç”¨æ¨¡å‹å¤§å°ç›¸å…³çš„è®¾ç½®
        config.__post_init__()
        
        # ä¿å­˜é…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if parsed_args.save_config:
            self.save_to_file(config, parsed_args.save_config)
        
        return config
    
    def create_default_configs(self, output_dir: str = "configs"):
        """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ä¸ºæ¯ç§æ¨¡å‹å¤§å°åˆ›å»ºé…ç½®
        for size in ["tiny", "small", "medium", "large"]:
            config = ModelConfig(model_size=size)
            config_file = output_path / f"{size}_config.yaml"
            self.save_to_file(config, config_file)
        
        # åˆ›å»ºè®­ç»ƒé…ç½®ç¤ºä¾‹
        train_config = ModelConfig(
            model_size="small",
            num_epochs=100,
            batch_size=8,
            learning_rate=5e-5,
            use_data_augmentation=True
        )
        self.save_to_file(train_config, output_path / "train_config.yaml")
        
        logger.info(f"é»˜è®¤é…ç½®æ–‡ä»¶å·²åˆ›å»ºåœ¨: {output_path}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºé…ç½®ç®¡ç†å™¨
    config_manager = ConfigManager()
    
    # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
    config_manager.create_default_configs()
    
    # ä»å‘½ä»¤è¡Œè§£æé…ç½®
    config = config_manager.parse_args_and_config()
    
    print("ğŸ”§ é…ç½®ä¿¡æ¯:")
    print(f"  æ¨¡å‹å¤§å°: {config.model_size}")
    print(f"  éšè—ç»´åº¦: {config.hidden_dim}")
    print(f"  æ‰¹æ¬¡å¤§å°: {config.batch_size}")
    print(f"  è®¾å¤‡: {config.device_auto}")
    print(f"  ä¼°ç®—å†…å­˜ä½¿ç”¨: {config.estimate_memory_usage()}") 