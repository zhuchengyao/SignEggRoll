#!/usr/bin/env python3
"""
æœ€å°åŒ– SignLLM è®­ç»ƒè„šæœ¬ - è§£å†³æ•°æ®æ ¼å¼é—®é¢˜ (ä¿®è®¢ç‰ˆ)

* ä½¿ç”¨ DataLoader æ›¿ä»£æ‰‹åŠ¨æ‰¹å¤„ç†
* é‡æ–°å®ä¾‹åŒ– CONFIG è€Œä¸æ˜¯ç›´æ¥è°ƒç”¨ __init__
* å¼•å…¥æ··åˆç²¾åº¦è®­ç»ƒ (AMP)
* ä¿å­˜å½“å‰ CONFIG åˆ° checkpoint

å…¶ä½™é€»è¾‘ä¿æŒä¸åŸè„šæœ¬ä¸€è‡´ã€‚
"""

import os
import sys
from pathlib import Path
from typing import List, Dict

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from signllm_model import SignLLM, ModelConfig, CONFIG  # æ–‡ä»¶åä¿æŒä¸å˜
from data_processor import MultilingualSignDataset


# --------------------------- Collate å‡½æ•° --------------------------- #

def collate_fn(batch: List[Dict]):
    """å°† dataset è¿”å›çš„æ ·æœ¬åˆ—è¡¨æ•´ç†æˆæ‰¹æ¬¡"""
    texts = [sample["text"] for sample in batch]
    poses = [sample["pose_sequence"] for sample in batch]
    poses = torch.stack(poses)  # å‡è®¾ dataset å·²ä¿è¯åºåˆ—é•¿åº¦ä¸€è‡´
    return {"texts": texts, "poses": poses}


# --------------------------- ä¸»å‡½æ•° --------------------------- #

def main():
    print("ğŸš€ æœ€å°åŒ– SignLLM è®­ç»ƒ (ä¿®è®¢ç‰ˆ)")
    print("=" * 60)

    # è®¾ç½®æ¨¡å‹å¤§å° (å¯é€‰: "tiny", "small", "medium", "large")
    MODEL_SIZE = "medium"

    # é‡æ–°å®ä¾‹åŒ– CONFIG, å¹¶æ›¿æ¢å…¨å±€å¼•ç”¨
    global CONFIG
    CONFIG = ModelConfig(MODEL_SIZE)

    # è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")

    # åˆ›å»ºæ¨¡å‹
    print("ğŸ“¦ åˆ›å»ºæ¨¡å‹â€¦")
    model = SignLLM(languages=["ASL"]).to(device)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ“Š å‚æ•°é‡: {total_params:,} ({total_params/1_000_000:.1f}M)")

    # åˆ›å»ºæ•°æ®é›† & æ•°æ®åŠ è½½å™¨
    print("ğŸ“š æ„å»ºæ•°æ®é›†â€¦")
    dataset = MultilingualSignDataset(
        data_dirs={"ASL": "datasets/signllm_data_complete"},
        languages=["ASL"],
        split="dev",
        max_sequence_length=256,
        pose_dim=CONFIG.pose_dim,
    )
    print(f"ğŸ“Š æ ·æœ¬æ•°: {len(dataset)}")

    loader = DataLoader(
        dataset,
        batch_size=2,
        shuffle=True,
        num_workers=2,
        collate_fn=collate_fn,
    )

    # ä¼˜åŒ–å™¨ & æŸå¤±
    optimizer = optim.AdamW(model.parameters(), lr=1e-4)
    criterion = nn.MSELoss()
    scaler = torch.amp.GradScaler(device.type)

    # è®­ç»ƒ
    epoch_num = 10
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒâ€¦")
    model.train()

    for epoch in range(epoch_num):
        print(f"\nğŸ“… Epoch {epoch + 1}/{epoch_num}")
        epoch_loss = 0.0
        for batch in tqdm(loader, desc=f"Epoch {epoch + 1}"):
            batch_texts = batch["texts"]
            target_poses = batch["poses"].to(device)

            with torch.amp.autocast(device.type):
                pred_poses, _ = model(
                    texts=batch_texts,
                    language="ASL",
                    mode="mlsf",
                    max_length=target_poses.size(1),
                )
                loss = criterion(pred_poses, target_poses)

            optimizer.zero_grad()
            scaler.scale(loss).backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            scaler.step(optimizer)
            scaler.update()

            epoch_loss += loss.item()

        avg_loss = epoch_loss / len(loader)
        print(f"ğŸ“Š Epoch {epoch + 1} å¹³å‡æŸå¤±: {avg_loss:.6f}")

        # ä¿å­˜æ£€æŸ¥ç‚¹
        checkpoint_dir = Path("checkpoints/eggroll_train")
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        checkpoint = {
            "epoch": epoch + 1,
            "config": CONFIG.__dict__,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            "loss": avg_loss,
        }
        ckpt_path = checkpoint_dir / f"epoch_{epoch + 1}.pth"
        torch.save(checkpoint, ckpt_path)
        print(f"ğŸ’¾ å·²ä¿å­˜æ£€æŸ¥ç‚¹: {ckpt_path}")

    print("\nâœ… è®­ç»ƒå®Œæˆï¼")

    # ç®€å•æ¨ç†æµ‹è¯•
    print("\nğŸ” æ¨ç†æµ‹è¯•â€¦")
    model.eval()
    with torch.no_grad():
        test_texts = ["Hello world"]
        test_poses, _ = model(texts=test_texts, language="ASL", mode="prompt2langgloss")
        print(f"âœ… æ¨ç†æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {test_poses.shape}")


if __name__ == "__main__":
    main()
