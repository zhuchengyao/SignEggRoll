#!/usr/bin/env python3
"""
SignLLM è®­ç»ƒå¯åŠ¨è„šæœ¬
"""

import os
import sys
import json
import argparse
from pathlib import Path
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from train_signllm import SignLLMTrainer
from utils import setup_logging


def check_data_availability(config):
    """æ£€æŸ¥æ•°æ®æ˜¯å¦å¯ç”¨"""
    dataset_path = Path(config['data']['dataset_path'])
    
    print(f"ğŸ” æ£€æŸ¥æ•°æ®è·¯å¾„: {dataset_path}")
    
    if not dataset_path.exists():
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        return False
    
    # æ£€æŸ¥è¯­è¨€ç›®å½•
    for language in config['data']['languages']:
        lang_dir = dataset_path / language
        if not lang_dir.exists():
            print(f"âŒ è¯­è¨€ç›®å½•ä¸å­˜åœ¨: {lang_dir}")
            return False
        
        # æ£€æŸ¥åˆ†å‰²ç›®å½•
        for split_name, split_value in config['data']['splits'].items():
            split_dir = lang_dir / split_value
            if not split_dir.exists():
                print(f"âŒ åˆ†å‰²ç›®å½•ä¸å­˜åœ¨: {split_dir}")
                return False
            
            # æ£€æŸ¥æ ·æœ¬æ•°é‡
            samples = list(split_dir.iterdir())
            sample_count = len([s for s in samples if s.is_dir()])
            print(f"âœ… {language}/{split_value}: {sample_count} ä¸ªæ ·æœ¬")
    
    return True


def check_environment():
    """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
    print("ğŸ”§ æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")
    
    # æ£€æŸ¥CUDA
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.get_device_name()}")
        print(f"   GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    # æ£€æŸ¥å†…å­˜
    import psutil
    memory = psutil.virtual_memory()
    print(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜: {memory.total / 1e9:.1f} GB (å¯ç”¨: {memory.available / 1e9:.1f} GB)")
    
    return True


def main():
    parser = argparse.ArgumentParser(description="å¯åŠ¨SignLLMè®­ç»ƒ")
    parser.add_argument("--config", type=str, default="configs/signllm_eggroll_config.json",
                       help="è®­ç»ƒé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--resume", type=str, default=None,
                       help="ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ")
    parser.add_argument("--debug", action="store_true",
                       help="è°ƒè¯•æ¨¡å¼ï¼ˆä½¿ç”¨æ›´å°‘æ•°æ®ï¼‰")
    parser.add_argument("--dry_run", action="store_true",
                       help="å¹²è¿è¡Œæ¨¡å¼ï¼ˆåªæ£€æŸ¥é…ç½®ï¼Œä¸å®é™…è®­ç»ƒï¼‰")
    
    args = parser.parse_args()
    
    print("ğŸš€ SignLLM è®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 50)
    
    # åŠ è½½é…ç½®
    config_path = Path(args.config)
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    print(f"ğŸ“‹ åŠ è½½é…ç½®: {config_path}")
    
    # è°ƒè¯•æ¨¡å¼è°ƒæ•´
    if args.debug:
        print("ğŸ› è°ƒè¯•æ¨¡å¼å¯ç”¨")
        config['data']['batch_size'] = 2
        config['training']['num_epochs'] = 2
        config['training']['save_every'] = 1
        config['training']['eval_every'] = 1
        config['logging']['log_every'] = 10
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        return
    
    # æ£€æŸ¥æ•°æ®
    if not check_data_availability(config):
        print("\nğŸ’¡ æç¤º: è¯·å…ˆå®Œæˆæ•°æ®è½¬æ¢:")
        print("python final_convert_data.py --data_dir datasets/final_data --output_dir datasets/signllm_data_complete --splits dev --language ASL")
        return
    
    # è®¾ç½®æ¢å¤è®­ç»ƒ
    if args.resume:
        config['checkpoint']['resume_from'] = args.resume
        print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤: {args.resume}")
    
    if args.dry_run:
        print("âœ… é…ç½®æ£€æŸ¥å®Œæˆï¼Œå¹²è¿è¡Œæ¨¡å¼ç»“æŸ")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config['checkpoint']['save_dir'], exist_ok=True)
    os.makedirs(config['logging']['log_dir'], exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(config['logging']['log_dir'])
    
    # ä¿å­˜ä½¿ç”¨çš„é…ç½®
    used_config_path = Path(config['checkpoint']['save_dir']) / "config_used.json"
    with open(used_config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"ğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {used_config_path}")
    
    # å¼€å§‹è®­ç»ƒ
    print("\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    print("=" * 50)
    
    try:
        trainer = SignLLMTrainer(config)
        trainer.train()
        
        print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: {config['checkpoint']['save_dir']}")
        print(f"ğŸ“Š æ—¥å¿—ä¿å­˜åœ¨: {config['logging']['log_dir']}")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 