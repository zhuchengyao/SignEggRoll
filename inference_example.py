#!/usr/bin/env python3
"""
SignLLMæ¨ç†è„šæœ¬ç¤ºä¾‹
"""

import torch
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from signllm_model import SignLLM, ModelConfig, CONFIG


def load_model_for_inference(checkpoint_path: str, model_size: str = "tiny", languages=["ASL"]):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ç”¨äºæ¨ç†
    
    Args:
        checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        model_size: æ¨¡å‹å¤§å°é…ç½®
        languages: æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
    Returns:
        model: åŠ è½½å¥½çš„æ¨¡å‹
    """
    # 1. é‡å»ºé…ç½®
    global CONFIG
    CONFIG.__init__(model_size)
    
    # 2. é‡å»ºæ¨¡å‹ç»“æ„
    model = SignLLM(languages=languages)
    
    # 3. åŠ è½½æƒé‡
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # 4. è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
    model.eval()
    
    print(f"âœ… æ¨¡å‹å·²åŠ è½½ï¼š{checkpoint_path}")
    print(f"ğŸ“Š è®­ç»ƒè½®æ¬¡ï¼š{checkpoint.get('epoch', 'Unknown')}")
    print(f"ğŸ“‰ è®­ç»ƒæŸå¤±ï¼š{checkpoint.get('loss', 'Unknown'):.6f}")
    
    return model


def inference_demo():
    """æ¨ç†æ¼”ç¤º"""
    print("ğŸš€ SignLLMæ¨ç†æ¼”ç¤º")
    print("=" * 50)
    
    # è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    checkpoint_path = "checkpoints/eggroll_train/epoch_10.pth"  # ä¿®æ”¹ä¸ºå®é™…è·¯å¾„
    model = load_model_for_inference(
        checkpoint_path=checkpoint_path,
        model_size="tiny",           # å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´
        languages=["ASL"]            # å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´
    )
    model.to(device)
    
    # æ¨ç†æµ‹è¯•
    print("\nğŸ” å¼€å§‹æ¨ç†...")
    with torch.no_grad():
        test_texts = [
            "Hello world",
            "How are you?",
            "Nice to meet you"
        ]
        
        for text in test_texts:
            print(f"\nğŸ“ è¾“å…¥æ–‡æœ¬: '{text}'")
            
            # ç”Ÿæˆæ‰‹è¯­å§¿æ€
            poses, quality_scores = model(
                texts=[text],
                language="ASL",
                mode="mlsf",
                max_length=100  # å¯è‡ªå®šä¹‰å¸§æ•°
            )
            
            print(f"ğŸ“Š ç”Ÿæˆå§¿æ€å½¢çŠ¶: {poses.shape}")
            print(f"ğŸ“ ç”Ÿæˆå¸§æ•°: {poses.shape[1]}")
            print(f"ğŸ¯ å¹³å‡è´¨é‡åˆ†æ•°: {quality_scores.mean().item():.4f}")


def save_minimal_checkpoint(full_checkpoint_path: str, output_path: str):
    """
    ä¿å­˜æœ€å°åŒ–çš„æ¨ç†æ£€æŸ¥ç‚¹ï¼ˆåªä¿ç•™å¿…è¦çš„æ¨¡å‹æƒé‡ï¼‰
    
    Args:
        full_checkpoint_path: å®Œæ•´è®­ç»ƒæ£€æŸ¥ç‚¹è·¯å¾„
        output_path: è¾“å‡ºçš„æœ€å°æ£€æŸ¥ç‚¹è·¯å¾„
    """
    # åŠ è½½å®Œæ•´æ£€æŸ¥ç‚¹
    full_checkpoint = torch.load(full_checkpoint_path, map_location='cpu')
    
    # åˆ›å»ºæœ€å°æ£€æŸ¥ç‚¹ï¼ˆåªä¿ç•™æ¨ç†å¿…éœ€çš„ä¿¡æ¯ï¼‰
    minimal_checkpoint = {
        'model_state_dict': full_checkpoint['model_state_dict'],
        'model_config': {
            'model_size': 'tiny',  # éœ€è¦æ‰‹åŠ¨æŒ‡å®šæˆ–ä»è®­ç»ƒè®°å½•ä¸­è·å–
            'languages': ['ASL']
        },
        'training_info': {
            'epoch': full_checkpoint.get('epoch'),
            'final_loss': full_checkpoint.get('loss')
        }
    }
    
    # ä¿å­˜æœ€å°æ£€æŸ¥ç‚¹
    torch.save(minimal_checkpoint, output_path)
    
    # è®¡ç®—å¤§å°å·®å¼‚
    import os
    full_size = os.path.getsize(full_checkpoint_path) / 1024 / 1024  # MB
    minimal_size = os.path.getsize(output_path) / 1024 / 1024  # MB
    
    print(f"ğŸ“¦ å®Œæ•´æ£€æŸ¥ç‚¹: {full_size:.2f} MB")
    print(f"ğŸ“¦ æœ€å°æ£€æŸ¥ç‚¹: {minimal_size:.2f} MB")
    print(f"ğŸ’¾ èŠ‚çœç©ºé—´: {full_size - minimal_size:.2f} MB ({(full_size-minimal_size)/full_size*100:.1f}%)")


if __name__ == "__main__":
    inference_demo()
    
    # å¯é€‰ï¼šåˆ›å»ºæœ€å°åŒ–æ£€æŸ¥ç‚¹
    # save_minimal_checkpoint(
    #     "checkpoints/eggroll_train/epoch_10.pth",
    #     "checkpoints/eggroll_train/minimal_epoch_10.pth"
    # ) 